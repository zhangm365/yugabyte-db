#!/usr/bin/env python
from __future__ import unicode_literals

import argparse
import shlex
import atexit
import json
import logging
import multiprocessing
import os
import re
import resource
import shutil
import subprocess
import sys
import time
import traceback
import uuid
import tempfile
import socket
import tarfile
import operator
import string
from datetime import datetime
from signal import SIGABRT, SIGINT, SIGKILL, SIGTERM, SIG_DFL, SIG_IGN, signal
from threading import Thread

# Version-dependent imports
PY_VERSION = sys.version_info[0]
if PY_VERSION < 3:
    import Queue as queue
    from urllib2 import Request, urlopen, URLError, HTTPError
    from urllib import urlencode
    from random import SystemRandom
    _sysrand = SystemRandom()
    PASSWORD_GENNERATOR = _sysrand.choice
else:
    import queue
    from urllib.request import Request, urlopen
    from urllib.error import URLError, HTTPError
    from urllib.parse import urlencode
    import secrets
    PASSWORD_GENNERATOR = secrets.choice

"""
Run `yugabyted` to start a single-node YugabyteDB process. If no options are specified,
`yugabyted` will assume the following default directory tree:

yugabyte
+-- var
    |
    +-- conf
        |   +-- yugabyted.conf
     +-- logs
         |   +-- master & tserver & yugaware
     +-- data
+-- bin
|   |   +-- yugabyted
|   |   +-- yb-master
|   |   +-- yb-tserver
|   |   +-- ...
+-- ui
|   |   +-- bin...
|   |   +-- ...
"""
# OS constants
OS_DETAILS = os.uname()
OS_NAME = OS_DETAILS[0]

# Script constants.
SCRIPT_NAME = os.path.basename(__file__)
YUGABYTE_DIR = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
TRUE_CHOICES = ["true", "True", "t", "T", "yes", "Yes", "y", "Y", "1"]
FALSE_CHOICES = ["false", "False", "f", "F", "no", "No", "n", "N", "0"]
BOOL_CHOICES = TRUE_CHOICES + FALSE_CHOICES
FAULT_TOLERANCE_CHOICES = ["zone", "region", "cloud"]
START_FAULT_TOLERANCE_CHOICES = ["none", "zone", "region", "cloud"]
SLACK_LINK = "https://www.yugabyte.com/slack"
COMMUNITY_REWARDS_LINK = "https://www.yugabyte.com/community-rewards/"
HELP_LINK = "https://docs.yugabyte.com/latest/faq/"
YUGABYTED_LINK = "https://docs.yugabyte.com/preview/reference/configuration/yugabyted/"
YUGABYTED_START = "https://docs.yugabyte.com/preview/reference/configuration/yugabyted/#start"
GENERATE_SERVER_CERTS = "https://docs.yugabyte.com/preview/secure/tls-encryption/\
server-certificates/#create-the-server-certificates"
DEFAULT_DEMO_DATABASE = "northwind"
DEFAULT_FAULT_TOLERANCE = "zone"
DEFAULT_START_FAULT_TOLERANCE = "none"
SAMPLE_DATA_LINKS = {
    "retail": "https://docs.yugabyte.com/latest/quick-start/explore-ysql/",
    "chinook": "https://docs.yugabyte.com/latest/sample-data/chinook/",
    "sports": "https://docs.yugabyte.com/latest/sample-data/sportsdb/",
    "northwind": "https://docs.yugabyte.com/latest/sample-data/northwind/"
}
EXIT_SIGNALS = (SIGABRT, SIGINT, SIGTERM)
REQUIRED_TRANSPARENT_HUGEPAGES_LINUX = "always"
REQUIRED_LOOPBACK_ADDRESSES = [
    '127\.0\.0\.2',
    '127\.0\.0\.3',
    '127\.0\.0\.4',
    '127\.0\.0\.5',
    '127\.0\.0\.6',
    '127\.0\.0\.7'
]
MAX_PROC = {
    'Linux' : 12000,
    'Darwin' : 2500,
}
PREREQS_ERROR_MSGS = {
    'open_files' :'open files ulimits value set low. Please set soft and hard limits to 1048576.',
    'max_user_processes' :'max user processes ulimits value set low.' \
        ' Please set soft and hard limits to {}.'.format(MAX_PROC[OS_NAME]),
    'transparent_hugepages' :'Transparent hugepages disabled. Please enable transparent_hugepages.',
    'ntp/chrony' :'ntp/chrony package is missing for clock synchronization. For centos 7, ' +
        'we recommend installing either ntp or chrony package and for centos 8, ' +
        'we recommend installing chrony package.',
}
QUICK_START_LINKS = {
    'mac' : 'https://docs.yugabyte.com/preview/quick-start/',
    'linux' : 'https://docs.yugabyte.com/preview/quick-start/linux/',
}
LINUX_PREREQS_CMDS = {
    'transparent_hugepages' : 'cat /sys/kernel/mm/transparent_hugepage/enabled',
    'ntp' : 'which ntpd',
    'chrony' : 'which chronyd',
    'openssl' : 'which openssl',
}
MAC_PREREQS_CMDS = {
}
CONFIG_LINK = "https://docs.yugabyte.com/latest/deploy/manual-deployment/system-config"

# Help Message Constants
PREFIX = {
    'yugabyted' : "YugabyteDB command-line interface for creating" +
                    " and configuring YugabyteDB cluster.",
    'start' : "Install YugabyteDB and start a single node cluster.\n\n" +
                "Use --join flag to join other nodes that are part of the same cluster.",
    'stop' : "",
    'destroy' : "",
    'status' : "",
    'version' : "",
    'collect_logs' : "",
    'configure' : "",
    'configure data_placement': "",
    'configure encrypt_at_rest': "",
    'configure admin_operation': "",
    'connect' : "",
    'connect ycql' : "",
    'connect ysql' : "",
    'demo' : "",
    'demo connect' : "",
    'demo destroy' : "",
    'cert' : "",
    'cert generate_server_certs' : "",
}

USAGE = {
    'yugabyted' : "yugabyted [command] [flags]",
    'start' : "yugabyted start [flags]",
    'stop' : "yugabyted stop [flags]",
    'destroy' : "yugabyted destroy [flags]",
    'status' : "yugabyted status [flags]",
    'version' : "yugabyted version [flags]",
    'collect_logs' : "yugabyted collect_logs [flags]",
    'configure' : "yugabyted configure [command] [flags]",
    'configure data_placement': "yugabyted configure data_placement [flags]",
    'configure encrypt_at_rest': "yugabyted configure encrypt_at_rest [flags]",
    'configure admin_operation' : "yugabyted admin_operation [flags]",
    'connect' : "yugabyted connect [command] [flags]",
    'connect ycql' : "yugabyted connect ycql [flags]",
    'connect ysql' : "yugabyted connect ysql [flags]",
    'demo' : "yugabyted demo [command] [flags]",
    'demo connect' : "yugabyted demo connect [flags]",
    'demo destroy' : "yugabyted demo destroy [flags]",
    'cert' : "yugabyted cert [command] [flags]",
    'cert generate_server_certs' : "yugabyted cert generate_server_certs [flag]",
}

EXAMPLE = {
    'start' : "# Create a single-node local cluster:\n" +
              "yugabyted start\n\n"+
              "# Create a single-node locally and join other nodes " +
              "that are part of the same cluster:\n" +
              "yugabyted start --join=host:port,[host:port]\n\n" +
              "# Create a secure cluster:\n" +
              "yugabyted start --secure --certs_dir=<path_to_certs_dir>\n\n",
    'stop' : "",
    'destroy' : "",
    'status' : "",
    'version' : "",
    'collect_logs' : "",
    'cert' : "# Create node sever certificates:\n" +
             "yugabyted cert generate_server_certs --hostnames=<comma_seperated_hostnames>\n\n",
    'configure' : "# Configure a multi-zone cluster:\n" +
                  "yugabyted configure data_placement --fault_tolerance=zone\n\n" +
                  "# Enable encryption at rest:\n" +
                  "yugabyted configure encrypt_at_rest --enable\n\n" +
                  "For more examples use 'yugabyted configure [command] -h'",
    'data_placement' : "# Configure a multi-zone cluster:\n" +
                       "yugabyted configure data_placement --fault_tolerance=zone\n\n" +
                       "# Configure a multi-region cluster:\n" +
                       "yugabyted configure --fault_tolerance=region\n\n" +
                       "# Configure a multi-zone cluster with specified placemenrt info and rf:\n" +
                       "yugabyted configure --fault_tolerance=zone " +
                       "--constraint_value=cloud1.region1.zone1,cloud2.region2.zone2," +
                       "cloud3.region3.zon3 --rf=3\n\n",
    'encrypt_at_rest' : "# Enable encryption at rest for a cluster:\n" +
                        "yugabyted configure encrypt_at_rest --enable\n\n" +
                        "# Disable encryption at rest for a cluster:\n" +
                        "yugabyted configure encrypt_at_rest --disable\n\n",
    'admin_operation' : "# Execute yb-admin command on the YugabyteDB cluster:\n" +
                         "yugabyted configure admin_operation --command 'get_universe_config'\n\n",
}

EPILOG_COMMON = "Run '{} [command] -h' for help with specific commands.".format(SCRIPT_NAME)

EPILOG_SPECIFIC = {
    'start' : "Use conf file to configure advanced flags. Learn more about advanced flags " +
                "refer to the docs page: {}.\n\n".format(YUGABYTED_START),
    'stop' : "",
    'destroy' : "",
    'status' : "",
    'version' : "",
    'collect_logs' : "",
    'configure' : "",
    'cert' : "",
}

# YugabyteDB configs.
IP_ANY = "0.0.0.0"
IP_LOCALHOST = "127.0.0.1"
DEFAULT_BIND_IP = IP_ANY
DEFAULT_MASTER_RPC_PORT = 7100
DEFAULT_TSERVER_RPC_PORT = 9100
DEFAULT_MASTER_WEBSERVER_PORT = 7000
DEFAULT_TSERVER_WEBSERVER_PORT = 9000
DEFAULT_YSQL_PORT = 5433
DEFAULT_YCQL_PORT = 9042
DEFAULT_WEBSERVER_PORT = 7200
DEFAULT_YUGABYTED_UI_PORT = 15433
DEFAULT_CALLHOME = True
DEFAULT_YSQL_USER = "yugabyte"
DEFAULT_YSQL_PASSWORD = "yugabyte"
DEFAULT_YSQL_DB = "yugabyte"
DEFAULT_CLOUD_PROVIDER = "cloud1"
DEFAULT_CLOUD_REGION = "datacenter1"
DEFAULT_CLOUD_ZONE = "rack1"
YSQL_PASSWORD_LENGTH_WARNING = "Warning: Your 'YSQL_PASSWORD' length is greater than 99 characters.\
Please set 'PGPASSWORD' in environment variables to use 'bin/ysqlsh'."
DEFAULT_YCQL_USER = "cassandra"
DEFAULT_YCQL_PASSWORD = "cassandra"
DEFAULT_YCQL_KEYSPACE = None
VERSION_METADATA_PATH = os.path.join(YUGABYTE_DIR, "version_metadata.json")
YUGABYTE_API_CLIENT_PROGRAMS = {
    "ysql": "ysqlsh",
    "ycql": "ycqlsh",
}
YB_NUM_SHARDS_PER_TSERVER = 1
YSQL_NUM_SHARDS_PER_TSERVER = 1
METRICS_SNAPSHOT_LIST = [
    "handler_latency_yb_tserver_TabletServerService_Read_count",
    "handler_latency_yb_tserver_TabletServerService_Write_count",
    "handler_latency_yb_tserver_TabletServerService_Read_sum",
    "handler_latency_yb_tserver_TabletServerService_Write_sum",
    "disk_usage", "cpu_usage", "node_up"
]

# YugaWare configs. These have their own separate subdirectory to preserve our itest flow.
YUGAWARE_DIR = os.path.join(YUGABYTE_DIR, "ui")
YUGAWARE_BIN_DIR = os.path.join(YUGAWARE_DIR, "bin")
YUGAWARE_CONF = os.path.join(YUGAWARE_DIR, "conf/application.yugabyted.conf")
WEBSERVER_DB = "system_platform"
DEMO_DB_PREFIX = "yb_demo_"

BREW_CONF_FILE = "/usr/local/etc/yugabyted.conf"

ALERT_WARNING = "Warning"
ULIMIT_ERR_CODE = "LOW_ULIMITS"
TS_MASTER_ADDRS_FLAG = "tserver_master_addrs"

start_time_sec = time.time()

# Finds the path where a particular file is present from
# amongst the supplied paths.
def search_file_in_paths(dir_candidates, file_name):
    for candidate in dir_candidates:
        if os.path.exists(os.path.join(candidate, file_name)):
            Output.log("Found directory {} for"
                        " file {}".format(candidate, file_name))
            return os.path.join(candidate, file_name)

    # If post_install.sh script isn't found then don't error out
    # The caller assumes that the environment is dev and skips
    # performing the post installation steps
    if(file_name == "post_install.sh"):
        return None

    Output.log_error_and_exit(
        "Yugabyte {} file not found in paths {}. Please check "
        "the paths.".format(file_name, dir_candidates)
    )

# Checks if all given files exist in the given path
def check_files_in_path(path, files):
    has_error = False

    for file in files:
        if not os.path.exists(os.path.join(path, file)):
            has_error = True
            Output.log("{} file not found.".format(os.path.join(path, file)))

    return not has_error

# Finds the path of a particular YB binary
def find_binary_location(binary_name):
    # Default if tar is downloaded
    dir_candidates = [
        os.path.join(YUGABYTE_DIR, "bin")
    ]

    # Development environment
    dir_candidates += [
        os.path.join(YUGABYTE_DIR, "build", "latest", "bin"),
    ]

    # Development environment for UI
    dir_candidates += [
        os.path.join(YUGABYTE_DIR, "build", "latest", "gobin"),
    ]

    return search_file_in_paths(dir_candidates, binary_name)

# Finds the path of the sample data
def find_sample_data_location(data_file):
    # Default if tar is downloaded
    dir_candidates = [
        os.path.join(YUGABYTE_DIR, "share")
    ]

    # Development environment
    dir_candidates += [
        os.path.join(YUGABYTE_DIR, "sample")
    ]

    return search_file_in_paths(dir_candidates, data_file)

# Finds the path of the version_metadata.json file
def find_version_metadata_location(version_file):
    # Default if tar is downloaded
    dir_candidates = [
        os.path.join(YUGABYTE_DIR)
    ]

    # Development environment
    dir_candidates += [
        os.path.join(YUGABYTE_DIR, "build", "latest")
    ]

    return search_file_in_paths(dir_candidates, version_file)

# Creates the Head Title for yugabyted CLI
def get_cli_title():
    title = Output.make_green(Output.make_green("Yugabyted CLI") + ": YugabyteDB command line")
    extra_len = len(Output.make_green(""))
    div_line = "+" + "-" * 98 + "+" + "\n"
    cli_title = div_line
    cli_title += ("| {:^" + str(105 + extra_len) + "} |\n").format(title)
    cli_title += div_line
    return cli_title

class ControlScript(object):
    def __init__(self):
        self.configs = None
        self.processes = {}
        self.stop_callhome = False
        self.alerts = []
        self.script = None
        self.setup_env_init = EnvBasedCredentials()

    # Starts YugabyteDB node.
    def start(self):
        if self.script.is_running():
            Output.print_out("{} is already running!".format(SCRIPT_NAME))
            sys.exit(1)

        Output.print_and_log("Starting {}...".format(SCRIPT_NAME))
        self.set_env_vars()

        if self.configs.temp_data.get("background"):
            # In daemon mode, self.daemonize() forks. The child process then executes
            # normal control flow. The parent process waits for the child process until
            # a status message can be printed to the terminal and then exits within daemonize.
            self.daemonize()
        self.script.write_pid(os.getpid())

        self.set_signals(self.kill_children)
        atexit.register(self.kill_children)
        Output.script_exit_func = self.kill_children

        self.start_processes()

    # Kills all processes related to yugabyted
    def kill_all_procs(self):
        pid = self.script.get_pid()
        if pid:
            pgid = os.getpgid(pid)
            if not pgid:
                Output.log("PGID could not be found for {} process".format(SCRIPT_NAME) +
                    "with PID {}. Is {} running?".format(pid, SCRIPT_NAME))
                return ("No PGID", pid)
            else:
                try:
                    os.killpg(pgid, SIGTERM)
                except OSError as err:
                    return (err, pid)
        self.script.delete_pidfile()
        return (None, pid)

    # Kills currently running yugabyted process if it exists.
    def stop(self, *args):
        (err, pid) = self.kill_all_procs()
        if err:
            Output.log_error_and_exit(
                "Failed to shut down {}: {}. Please check PID in {}".format(
                    SCRIPT_NAME, err, self.script.pidfile))
        elif pid:
            self.script.wait_until_stop(pid)
            Output.print_out("Stopped {} using config {}.".format(SCRIPT_NAME, self.conf_file))
        sys.exit(0)

    # Prints status of YugabyteDB.
    def status(self):
        if len(os.listdir(self.configs.saved_data.get("data_dir"))) != 0:
            Output.print_out(self.get_status_string())
        else:
            Output.print_out("{} is not running.".format(SCRIPT_NAME))

    # Destroy the YugabyteDB cluster.
    def destroy(self):
        (err, pid) = self.kill_all_procs()
        if err:
            Output.log_error_and_exit(
                "Failed to shut down {}: {}. Please check PID in {}".format(
                    SCRIPT_NAME, err, self.script.pidfile))
        elif pid:
            self.script.wait_until_stop(pid)
            Output.print_out("Stopped {} using config {}.".format(SCRIPT_NAME, self.conf_file))
        logpath = self.configs.saved_data.get("log_dir")
        datapath = self.configs.saved_data.get("data_dir")
        gen_certs_dir = self.configs.saved_data.get("gen_certs_dir")
        certs_dir = self.configs.saved_data.get("certs_dir")

        if (self.conf_file == BREW_CONF_FILE):
            Output.print_out("{} destroy is not supported for brew installations.".format(
                SCRIPT_NAME))
            return

        if os.path.isdir(logpath):
            shutil.rmtree(logpath)
            Output.print_out("Deleted logs at {}.".format(logpath))

        if os.path.isdir(datapath):
            shutil.rmtree(datapath)
            Output.print_out("Deleted data at {}.".format(datapath))

        if os.path.isdir(gen_certs_dir):
            shutil.rmtree(gen_certs_dir)
            Output.print_out("Deleted generated certs at {}.".format(gen_certs_dir))

        if os.path.isdir(certs_dir):
            shutil.rmtree(certs_dir)
            Output.print_out("Deleted certs at {}.".format(certs_dir))

        if os.path.exists(self.conf_file):
            os.remove(self.conf_file)
            Output.print_out("Deleted conf file at {}.".format(self.conf_file))

        sys.exit(0)

    # Prints YugabyteDB version.
    def version(self):
        VERSION_METADATA_PATH = find_version_metadata_location("version_metadata.json")
        print(VERSION_METADATA_PATH)
        with open(VERSION_METADATA_PATH) as metadata:
            data = json.load(metadata)
            title = "Version".format(SCRIPT_NAME)
            output = "\n" + "-" * 70 + "\n"
            output += ("| {:^66} |\n").format(title)
            output += "-" * 70 + "\n"
            build = data.get("build_number")
            try:
                version = "{}-b{}".format(data.get("version_number"), int(build))
            except ValueError as e:
                version = "{} ({})".format(data.get("version_number"), build)
            for k, v in [
                    ("Version", version),
                    ("Build Time", data.get("build_timestamp")),
                    ("Build Hash", data.get("git_hash"))]:
                output_k = Output.make_yellow(k)
                extra_len = len(Output.make_yellow(""))
                output += ("| {:" + str(15 + extra_len) + "}: {:<49} |\n").format(output_k, v)
            output += "-" * 70 + "\n"
            Output.print_out(output)

    # Starts an interactive YSQL shell.
    def connect_ysql(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{} is not running. Cannot connect to YSQL.".format(SCRIPT_NAME))
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        ysql_proxy.connect()

    # Starts an interactive YCQL shell.
    def connect_ycql(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{} is not running. Cannot connect to YCQL.".format(SCRIPT_NAME))
        if self.configs.saved_data.get("secure"):
            self.setup_env_init.setup_cert_file_path(self.configs.
                            saved_data.get("ca_cert_file_path"))
        ycql_proxy = YcqlProxy(ip=self.advertise_ip(),
                        port=self.configs.saved_data.get("ycql_port"),
                        secure=self.configs.saved_data.get("secure"))
        ycql_proxy.connect()

    # Creates demo database and starts an interactive shell into it. Destroys the sample database
    # after shell quits.
    def demo(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{0} is not running. Please run `{0} start` before starting a demo.".format(
                    SCRIPT_NAME))

        db_name = DEMO_DB_PREFIX + self.configs.temp_data.get("demo_db")
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        if ysql_proxy.db_exists(db_name):
            Output.log_error_and_exit(
                "Demo is already running. Concurrent demos are currently unsupported.")
        # TODO: Race condition currently exists when running demo too close to each other. This
        # will be solved when concurrent isolated demos are implemented.
        Output.print_out("Now creating demo database")
        self.create_demo()

        # Ignore kill SIGINT to match normal ysqlsh and psql behavior.
        signal(SIGINT, SIG_IGN)
        signal(SIGABRT, self.destroy_demo)
        signal(SIGTERM, self.destroy_demo)
        atexit.register(self.destroy_demo)
        self.connect_demo()
        self.set_signals(SIG_DFL)

    # Create target demo database if it does not exist.
    def create_demo(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{0} is not running. Please run `{0} start` before starting a demo.".format(
                    SCRIPT_NAME))

        demo_db = self.configs.temp_data.get("demo_db")
        db_name = DEMO_DB_PREFIX + demo_db
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        if ysql_proxy.db_exists(db_name):
            Output.print_out("Demo database {} already exists.".format(demo_db))
            return

        Output.print_out(
            "Initializing {} demo database. This may take up to a minute...".format(demo_db))
        # Create demo database.
        Output.log("Creating database {}...".format(db_name))
        ysql_proxy.create_db(db_name)

        # Populate demo database.
        Output.log("Populating {} with sample data...".format(db_name))
        files = []
        for name in Configs.get_demo_info()[demo_db]["files"]:
            files.append(os.path.join(find_sample_data_location(name)))
        ysql_proxy.load_files(files, db=db_name)

        msg = "Successfully loaded sample database!"
        Output.print_and_log(msg)

    # Run YSQL shell in target demo database.
    def connect_demo(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{0} is not running. Please run `{0} start` before starting a demo.".format(
                    SCRIPT_NAME))

        demo_db = self.configs.temp_data.get("demo_db")
        db_name = DEMO_DB_PREFIX + demo_db
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        if not ysql_proxy.db_exists(db_name):
            self.create_demo()

        # Ignore kill SIGINT to match normal ysqlsh and psql behavior.
        signal(SIGINT, SIG_IGN)
        website = Output.make_underline(SAMPLE_DATA_LINKS[demo_db])
        Output.print_out(Configs.get_demo_info()[demo_db]["examples"])
        Output.print_out(
            "For more, go to {}\n".format(website)
        )
        ysql_proxy.connect(db=db_name)

    # Destroy target demo database if it exists.
    def destroy_demo(self, signum=None, frame=None):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{0} is not running. Please run `{0} start` before starting a demo.".format(
                    SCRIPT_NAME))

        demo_db = self.configs.temp_data.get("demo_db")
        db_name = DEMO_DB_PREFIX + demo_db
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        if ysql_proxy.db_exists(db_name):
            ysql_proxy.drop_db(db_name)
        msg = "Deleted demo database {}.".format(demo_db)
        Output.print_and_log(msg)

    def collect_logs(self):
        logpath = self.configs.saved_data.get("log_dir")
        if not os.path.exists(logpath):
            Output.print_and_log("No logs directory at {}".format(logpath))
            return
        tmpprefix = "yugabyted-{}.tar.gz".format(str(datetime.now()).replace(" ", "-"))
        tarpath = os.path.join(os.path.expanduser('~'), tmpprefix)
        with tarfile.open(name=tarpath, mode='w:gz', dereference=True) as archive:
            archive.add(logpath)

        if self.configs.temp_data.get("collect_logs_stdout"):
            Output.log("Logs are packaged into {}".format(tarpath))
            if tarfile.is_tarfile(tarpath):
                with open(tarpath, 'rb') as tar_fd:
                    if sys.version_info[0] == 3:
                        sys.stdout.buffer.write(tar_fd.read())
                    else:
                        sys.stdout.write(tar_fd.read())
        else:
            Output.print_and_log("Logs are packaged into {}".format(tarpath))

    # Configuring the data placement policy
    def configure_data_placement(self):
        if not self.script.is_running():
            Output.log_error_and_exit(Output.make_red("ERROR") + ": No YugabyteDB node " +
                "is running in the data_dir {}".format(self.configs.saved_data.get("data_dir")))

        fault_tolerance = self.configs.temp_data.get("fault_tolerance")
        replication_factor = self.configs.temp_data.get("replication_factor")

        if fault_tolerance == "cloud":
            Output.log_error_and_exit("Cloud based fault tolerance is not supported yet.")

        current_masters = self.get_all_masters()
        current_masters = [ master.split(':')[0] for master in current_masters ]
        leader_master = self.get_leader_master().split(':')[0]
        master_addr = "{}:{}".format(leader_master,
                                        self.configs.saved_data.get("master_rpc_port"))

        leader_master_http_endpoint = "{}:{}".format(leader_master,
                        self.configs.saved_data.get("master_webserver_port"))
        placement_locations = self.get_all_masters_locations(leader_master_http_endpoint)

        if len(placement_locations) < int(replication_factor):
            Output.print_and_log(msg = Output.make_red("ERROR") + ": not enough nodes to set-up " +
                                "a RF-{} cluster".format(replication_factor), level=logging.ERROR)
            sys.exit(1)

        new_masters = self.get_new_valid_masters(current_masters,
                leader_master, placement_locations)

        masters_to_remove = [ master for master in current_masters if master not in new_masters ]
        masters_to_add = [ master for master in new_masters if master not in current_masters ]

        if not masters_to_remove and not masters_to_add:
            Output.log("Desired fault tolerance is already setup. No Masters to move.")
        else :
            track_masters_to_remove = masters_to_remove[:]
            track_masters_to_add = masters_to_add[:]
            if masters_to_remove and masters_to_add:
                for i in range(len(masters_to_remove)):
                    self.replace_master(master_addr, masters_to_remove[i], masters_to_add[i])
                    track_masters_to_remove.remove(masters_to_remove[i])
                    track_masters_to_add.remove(masters_to_add[i])

            if len(track_masters_to_add) != 0:
                for master in track_masters_to_add:
                    self.add_master_for_data_placement(master_addr, master)

            if len(track_masters_to_remove) != 0:
                for master in track_masters_to_remove:
                    self.remove_master_for_data_placement(master_addr, master)

        current_masters = self.get_all_masters()
        placement_info = self.configs.temp_data.get("constraint_value")
        if not placement_info:
            placement_info = []
            for master in current_masters:
                placement_info.append(placement_locations[master.split(":")[0]])
            placement_info = ",".join(placement_info)

        if not self.is_placement_constraint_valid_length(placement_info):
            Output.log_error_and_exit("FAILED: Invalid number of placement constraint specified.")

        if not self.is_placement_constraint_valid_values(placement_locations, placement_info):
            Output.log_error_and_exit("FAILED: Invalid values provided for placement constraint.")

        master_addresses = ",".join(current_masters)

        if not YBAdminProxy.modify_placement_info(master_addresses,
                                                    placement_info, replication_factor):
            Output.log_error_and_exit("FAILED: Setting of placement info of masters")
        else:
            Output.log("Configure step was successful.")

        status_details = self.get_configure_status_details(placement_locations, new_masters)

        Output.print_out(self.get_status_string_common(status_details[0], status_details[1]))

    # Generate the node server certificates
    def cert_generate_server_certs(self):
        if self.check_openssl():
            Output.log_error_and_exit(Output.make_red("Error") + ": openssl not installed. " +
                "Can't create certificates.")

        gen_certs_dir = self.configs.saved_data.get("gen_certs_dir")
        root_certs_dir = os.path.join(gen_certs_dir, "root-ca")

        status_details = []
        if not self.generate_ca_certs(root_certs_dir=root_certs_dir):
            status_details = [
                (Output.make_yellow("Status"), "Cert generation failed. Please check the logs."),
            ]
            Output.print_out(self.get_status_string_common(status_details))
            sys.exit(1)

        hostnames = self.configs.temp_data.get("hostnames")
        hostnames = hostnames.split(',')

        generated_certs_hostnames = self.generate_node_server_certs(hostnames=hostnames,
                                                                    gen_certs_dir=gen_certs_dir)
        if len(generated_certs_hostnames):
            status_details = [
                (Output.make_yellow("Status"), "Server nodes certs generation for hostnames " +
                                "{} successful.".format(",".join(generated_certs_hostnames))),
                (Output.make_yellow("Server node certs path"),
                        "Certs can be found at: {}".format(gen_certs_dir+"/<hostname>")),
            ]
        else:
            status_details = [
                (Output.make_yellow("Status"), "No certs generated. All hostnames already have " +
                                               "certs generated."),
                (Output.make_yellow("Server node certs path"),
                        "Certs can be found at: {}".format(gen_certs_dir+"/<hostname>")),
            ]

        Output.print_out(self.get_status_string_common(status_details))

    # Generate the root certificates
    def generate_ca_certs(self, root_certs_dir):
        generate_certs = False

        if os.path.isdir(root_certs_dir):
            if self.check_root_cert_files(root_certs_dir):
                Output.log("Found an existing root certs directory {}.".format(root_certs_dir) +
                    " Found appropriate files. Using the existing root certs.")
            else:
                Output.print_and_log(Output.make_yellow(Output.ANIMATION_WARNING + " WARNING:") +
                    " Found an existing root certs directory {}.".format(root_certs_dir) +
                    " Appropriate files not found. Removing these and creating new root certs." +
                    " Please recreate any server certs created with previous root certs.")
                shutil.rmtree(root_certs_dir)

                generate_certs = True
        else:
            generate_certs = True

        if generate_certs:
            Output.log("Creating root certs...")
            if not os.path.isdir(root_certs_dir):
                os.makedirs(root_certs_dir)

            status = OpenSSLProxy.generate_root_ca_certs(root_certs_dir=root_certs_dir)

            if not status:
                return False

        return True

    # Generate node server certififcates
    def generate_node_server_certs(self, hostnames, gen_certs_dir):
        root_certs_dir = os.path.join(gen_certs_dir, "root-ca")

        existing_certs_hostnames = []
        generated_certs_hostnames = []
        # Generate certs for each server node
        for hostname in hostnames:
            # Check whether the hostname is already present in the certs database or not.
            if self.check_hostname_in_root_ca_database(hostname=hostname,
                                                       root_certs_dir=root_certs_dir):
                existing_certs_hostnames.append(hostname)
                continue

            # Check whether the hostname cert folder is present or not
            node_certs_dir = os.path.join(gen_certs_dir, hostname)
            if os.path.isdir(node_certs_dir):
                Output.log("Found an existing cert directory {} for ".format(node_certs_dir) +
                    "hostname {}. But no data entry found in ".format(hostname) +
                    "root-ca certs database. Removing...")
                shutil.rmtree(node_certs_dir)

            status = OpenSSLProxy.generate_node_server_certs(root_certs_dir=root_certs_dir,
                hostname=hostname, server_cert_dir=node_certs_dir)

            if not status:
                status_details = [
                    (Output.make_yellow("Status"), "Server node cert generation failed for " +
                        "hostname {}. Please check the logs.".format(hostname)),
                ]
                Output.print_out(self.get_status_string_common(status_details))
                exit(1)
            else:
                generated_certs_hostnames.append(hostname)

        if len(existing_certs_hostnames):
            Output.print_and_log(Output.make_yellow(Output.ANIMATION_WARNING + " WARNING:") +
                " Hostnames {} ".format(Output.make_green(",".join(existing_certs_hostnames))) +
                "already have their certifcates generated according to root-ca certs database " +
                "index. Please use the previously generated certs. Skipping these hostnames....")


        return generated_certs_hostnames

    # Check if all root certificate files are present in a path or not
    def check_root_cert_files(self, path):
        root_certs_files = ["ca.crt", "ca.key", "ca.conf", "index.txt",
            "index.txt.attr", "serial.txt"]

        return check_files_in_path(path, root_certs_files)

    # Check if a hostname is present in the root-ca database
    def check_hostname_in_root_ca_database(self, hostname, root_certs_dir):
        root_ca_database_file = os.path.join(root_certs_dir, "index.txt")

        with open(root_ca_database_file, 'r') as certs_database_file:
            certs_database = certs_database_file.read()
            if hostname in certs_database:
                return True

        return False

    # Use the masters to check if the masters has the key with <key_id>.
    def is_key_in_all_masters(self, key_id):
        masters = ",".join(self.get_all_masters())

        # IPs of the masters which are currently in the cluster
        master_ips = [master.split(':')[0] for master in masters.split(',')]

        # Masters which have the key with id as key_id
        masters_with_key = YBAdminProxy.check_key_in_masters(master_addrs=masters, key_id=key_id)
        for i, master in enumerate(masters_with_key):
            master = master.split(':')[0].split()[1]
            masters_with_key[i] = master

        ret = True
        if masters_with_key < len(master_ips):
            ret = False

        for master in master_ips:
            if master not in masters_with_key:
                ret = False

        return ret

    # Use the masters to check if encryption at rest is enabled.
    def is_encryption_at_rest_enabled(self):
        masters = self.configs.saved_data.get("current_masters")
        result = YBAdminProxy.check_encryption(master_addrs=masters)

        if result is None:
            return None

        if "ENABLED" in result:
            return True
        else:
            return False

    # Configuring encryption at rest
    def configure_encrypt_at_rest(self):
        if not self.script.is_running():
            Output.log_error_and_exit(Output.make_red("ERROR") + ": No YugabyteDB node " +
                "is running in the data_dir {}".format(self.configs.saved_data.get("data_dir")))

        status_details = []
        has_errors = False

        # Enable encryption at rest.
        if self.configs.temp_data.get("enable_encrypt_at_rest"):
            Output.log("Trying to enable encryption at rest.")

            # Check whether the encryption at rest is already enabled.
            encryption_enabled = self.is_encryption_at_rest_enabled()
            if encryption_enabled is None:
                Output.log_error_and_exit("Error checking status of encryption-at-rest.")
            elif encryption_enabled:
                Output.log("Encryption at rest already enabled.")
                has_errors = True
                status_details = [
                    (Output.make_yellow("Status"), "Encryption at rest already enabled.")
                ]

            # Setting the key directory and name
            key_dir = os.path.join(self.configs.saved_data.get("data_dir"), "encrypt-keys")
            keyname = "encrypt_at_rest"

            if not has_errors:
                # Check openssl is installed in the machine or not.
                if self.check_openssl():
                    Output.log_error_and_exit(Output.make_red("Error") + ": openssl not " +
                        "installed. Can't create universe key for encryption.")

                # Generate the universe key.
                status = OpenSSLProxy.generate_key(key_dir=key_dir, keyname=keyname)

                if not status:
                    Output.log(Output.make_red("Error") + ": Universe key generation failed for " +
                            "encryption at rest.")
                    has_errors = True
                    status_details = [
                        (Output.make_yellow("Status"), "Universe key generation failed for " +
                            "enabling encryption at rest. Please check the logs.")
                    ]
                else:
                    masters = ",".join(self.get_all_masters())
                    key_id = str(uuid.uuid4())
                    key_path = key_dir + "/" + keyname + ".key"

                    # Copy the generated universe key to all the masters
                    if not has_errors and not YBAdminProxy.copy_key_to_masters(
                            master_addrs=masters, key_id=key_id, key_path=key_path):
                        Output.log(Output.make_red("Error") + ": cannot copy the " +
                            "generated key to the masters.")
                        has_errors = True
                        status_details = [
                            (Output.make_yellow("Status"), "Encryption at rest failed. " +
                                "Please check the logs."),
                        ]

                    # Check whether all masters have the key.
                    if not has_errors:
                        if not self.is_key_in_all_masters(key_id=key_id):
                            Output.log(Output.make_red("Error") + ": Universe key " +
                                "{} not found in all masters.".format(key_id))
                            has_errors = True
                            status_details = [
                                (Output.make_yellow("Status"), "Encryption at rest failed. " +
                                    "Please check the logs."),
                            ]
                        else:
                            Output.log("Copied key {} to all the masters".format(key_id))

                    # Enable encryption at rest.
                    if not has_errors and not YBAdminProxy.enable_encryption_using_key(
                            master_addrs=masters, key_id=key_id):
                        Output.log(Output.make_red("Error") + ": cannot enable " +
                            "encryption at rest.")
                        has_errors = True
                        status_details = [
                            (Output.make_yellow("Status"), "Encryption at rest failed. " +
                                "Please check the logs."),
                        ]

                    # Check whether the encryption at rest has been enabled or not.
                    if not has_errors:
                        encryption_enabled = self.is_encryption_at_rest_enabled()
                        if encryption_enabled is None:
                            Output.log_error_and_exit("Error checking status of " +
                                "encryption-at-rest.")
                        elif not encryption_enabled:
                            Output.log(Output.make_red("Error") + ": cannot enable " +
                                "encryption at rest.")
                            has_errors = True
                            status_details = [
                                (Output.make_yellow("Status"), "Encryption at rest failed. " +
                                    "Please check the logs."),
                            ]
                        else:
                            out = "Encryption at rest enabled with key: {}".format(key_id)
                            Output.log(out)
                            status_details = [
                                (Output.make_yellow("Status"), out),
                            ]

            Output.log("Deleting the universe key generated for encryption at rest.")
            if os.path.isdir(key_dir):
                shutil.rmtree(key_dir)
        # Disabling encryption at rest
        else:
            Output.log("Trying to disable encryption at rest.")

            # Check whether encryption at rest is already disabled.
            encryption_enabled = self.is_encryption_at_rest_enabled()
            if encryption_enabled is None:
                Output.log_error_and_exit("Error checking status of encryption-at-rest.")
            elif not encryption_enabled:
                Output.log("Encryption at rest is already disabled.")
                has_errors = True
                status_details = [
                    (Output.make_yellow("Status"), "Encryption at rest is already disabled.")
                ]

            masters = ",".join(self.get_all_masters())

            # Disable encryption at rest
            if not has_errors and not YBAdminProxy.disable_encryption(master_addrs=masters):
                Output.log(Output.make_red("Error") + ": cannot disable encryption at rest.")
                has_errors = True
                status_details = [
                    (Output.make_yellow("Status"), "Disabling encryption at rest failed. " +
                        "Please check the logs."),
                ]

            # Check whether encryption at rest has been disabled or not.
            if not has_errors:
                encryption_enabled = self.is_encryption_at_rest_enabled()
                if encryption_enabled is None:
                    Output.log_error_and_exit("Error checking status of encryption-at-rest.")
                elif encryption_enabled:
                    Output.log(Output.make_red("Error") + ": cannot disable encryption at rest.")
                    has_errors = True
                    status_details = [
                        (Output.make_yellow("Status"), "Disabling encryption at rest failed. " +
                            "Please check the logs."),
                    ]
                else:
                    out = "Encryption at rest disabled."
                    Output.log(out)
                    status_details = [
                        (Output.make_yellow("Status"), out),
                    ]

        Output.print_out(self.get_status_string_common(status_details))

    # handle the admin operations passthrough to yb-admin command.
    def configure_admin_operation(self, timeout=10):

        master_addrs = self.configs.temp_data.get("admin_operation_master_addresses")
        if not master_addrs:
            master_addrs = ",".join(self.get_all_masters())
        command = self.configs.temp_data.get("admin_command")
        command_args = command.split(" ")
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs]
        for cmd_var in command_args:
            cmd += [cmd_var]

        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)

        status_details = {}
        status_details = [(Output.make_yellow("Admin operation"),
                           "Find the response below."),]
        Output.print_out(self.get_status_string_common(status_details))
        if 0 == ret_code:
          Output.print_out(out)
        else:
          Output.log(err)
          Output.print_out(Output.make_red(err))

    # Check for openssl
    def check_openssl(self):
        openssl_check = run_process(shlex.split(LINUX_PREREQS_CMDS.get('openssl')))
        openssl_exit_code = openssl_check[2]
        return openssl_exit_code != 0

    # All Pre-requisites check for Linux
    def linux_prereqs_check(self):
        prereqs_failed = set()
        prereqs_warn = set()
        prereqs_failed_flag = False
        prereqs_warn_flag = False

        transparent_hugepages_check = run_process(shlex
                .split(LINUX_PREREQS_CMDS.get('transparent_hugepages')))
        transparent_hugepages = re.search("\[(.*)\]", transparent_hugepages_check[0]).group(1)
        if transparent_hugepages != REQUIRED_TRANSPARENT_HUGEPAGES_LINUX:
            prereqs_warn.add('transparent_hugepages')
            prereqs_warn_flag = True

        ntp_check = run_process(shlex.split(LINUX_PREREQS_CMDS.get('ntp')))
        chrony_check = run_process(shlex.split(LINUX_PREREQS_CMDS.get('chrony')))
        ntp_exit_code = ntp_check[2]
        chrony_exit_code = chrony_check[2]
        if ntp_exit_code != 0 and chrony_exit_code != 0:
            prereqs_warn.add('ntp/chrony')
            prereqs_warn_flag = True

        return (prereqs_failed_flag, prereqs_failed, prereqs_warn_flag, prereqs_warn)

    # All Pre-requistes check for MacOS
    def mac_prereqs_check(self):
        prereqs_failed = set()
        prereqs_warn = set()
        prereqs_failed_flag = False
        prereqs_warn_flag = False

        return (prereqs_failed_flag, prereqs_failed, prereqs_warn_flag, prereqs_warn)

    # Checks whether the prerequisites are met or not
    def prereqs_check(self, ulimits=False):
        help_msg = ""
        if OS_NAME == "Linux":
            check = self.linux_prereqs_check()
            help_msg = "Please review the \'Quick start for Linux\' docs and rerun "\
                "the start command: " + Output.make_underline(QUICK_START_LINKS['linux'])+'\n'
        else:
            check = self.mac_prereqs_check()
            help_msg+="Please review the \'Quick start for macOS\' docs and rerun "\
                "the start command: "+ Output.make_underline(QUICK_START_LINKS['mac'])+'\n'

        prereqs_failed_flag, prereqs_failed, prereqs_warn_flag, prereqs_warn = check

        msg = " System checks. Following pre-reqs are not met:\n"
        failed_msg = ""
        for prereq in prereqs_failed:
            failed_msg+=("- "+PREREQS_ERROR_MSGS[prereq]+"\n")
        warning_msg = ""
        warnings = []
        for prereq in prereqs_warn:
            warning_msg+=("- "+PREREQS_ERROR_MSGS[prereq]+"\n")
            warnings.append(PREREQS_ERROR_MSGS[prereq])
        ulimit_msg = {
            'open_files' :"- "+PREREQS_ERROR_MSGS['open_files']+"\n",
            'max_user_processes' :"- "+PREREQS_ERROR_MSGS['max_user_processes']+"\n",
        }

        final_msg = ""
        check_status = None
        if prereqs_failed_flag:
            final_msg += (Output.ANIMATION_FAIL + " " + Output.make_red("FAILED") + ": " + msg)
            final_msg += (failed_msg+warning_msg)
            if ulimits:
                for ulimit in ulimits:
                    final_msg+=ulimit_msg[ulimit]
            final_msg += ("\n"+help_msg+"\n")
            check_status = Output.ANIMATION_FAIL
        elif prereqs_warn_flag:
            final_msg = warnings
            if ulimits:
                for ulimit in ulimits:
                    final_msg.append(PREREQS_ERROR_MSGS[ulimit])
            final_msg.append(help_msg)
            check_status = Output.ANIMATION_WARNING
        elif ulimits:
            final_msg = []
            for ulimit in ulimits:
                final_msg.append(PREREQS_ERROR_MSGS[ulimit])
            final_msg.append(help_msg)
            check_status = Output.ANIMATION_WARNING
        else:
            final_msg = Output.ANIMATION_SUCCESS + " " + "System checks"
            check_status = Output.ANIMATION_SUCCESS

        result = {
            'msg' : final_msg,
            'status' : check_status,
        }

        return result

    # Checks yb-master and yb-tserver are running. Returns failed processes.
    # TODO: Check postmaster.pid.
    def get_failed_node_processes(self):
        failed_processes = []
        for process in ("master", "tserver"):
            if not ProcessManager.is_process_running(
                    process, self.configs.saved_data.get("data_dir")):
                failed_processes.append("yb-{}".format(process))
        return failed_processes

    # Called after receiving certain signals or on exit. Kills all subprocesses.
    def kill_children(self, signum=None, frame=None):
        if signum:
            Output.log("Received signal: {}".format(signum), logging.DEBUG)
        Output.print_and_log("Shutting down...")
        Output.console_access = False
        self.script.daemon_success.put(-1)
        cur_pid = os.getpid()
        pgid = os.getpgid(cur_pid)
        if not pgid:
            Output.log(
                "PGID could not be found for PID {}. Is {} running?".format(cur_pid, SCRIPT_NAME))
            os._exit(os.EX_OK)
        self.set_signals(SIG_DFL)

        for p in self.processes.values():
            p.delete_pidfile()
        self.script.delete_pidfile()

        try:
            # Kill process group instead of self.processes to ensure
            # any spawned child processes are killed. Use SIGKILL because YugaWare
            # requires KILL signal to terminate and nodes currently do not gracefully terminate.
            os.killpg(pgid, SIGKILL)
            Output.log(
                "{} may not have terminated properly... "
                "Please check PGID {}.".format(SCRIPT_NAME, pgid))
        except OSError as err:
            Output.log(
                "Failed to kill PGID {}... Is {} running?\n{}".format(pgid, SCRIPT_NAME, str(err)))

        # exit no matter what
        os._exit(os.EX_OK)

    def start_first_master_tserver(self, master_addresses):
        self.processes.get("master").start()

        was_already_setup = self.configs.saved_data.get("cluster_member", False)

        if was_already_setup:
            Output.log("Node was a member of some cluster before. "
                    "Skipping master setup")
        elif not self.setup_master():
            # TODO(sanketh): Make these all throw exceptions instead of excns + return values
            return "Failed to start master {}".format(SCRIPT_NAME)

        self.update_tserver_master_addrs()
        self.processes.get("tserver").start()
        if was_already_setup:
            Output.log("Node was a member of some cluster before. "
                    "Skipping tserver setup")
        elif not self.wait_tserver():
            return "Failed to start tserver {}".format(SCRIPT_NAME)

        if not was_already_setup:
            master_addresses = self.configs.saved_data.get("current_masters")
            universe_uuid = YBAdminProxy.get_cluster_uuid(master_addresses)
            if universe_uuid and universe_uuid != self.configs.saved_data["universe_uuid"]:
                self.configs.saved_data["universe_uuid"] = universe_uuid
                self.configs.save_configs()

        return None


    # Starts yb-master, yb-tserver, and yugaware processes.
    # After initializing, creates a callhome thread.
    def start_processes(self):
        bind_ip = self.configs.saved_data.get("advertise_address")
        advertise_ip = bind_ip if bind_ip != IP_ANY else IP_LOCALHOST
        master_rpc_port = self.configs.saved_data.get("master_rpc_port")
        join_ip = self.configs.saved_data.get("join")
        fault_tolerance = self.configs.saved_data.get("fault_tolerance")
        master_addresses  = "{}:{}".format(advertise_ip, master_rpc_port)
        if join_ip:
            master_addresses  = "{}:{},{}".format(join_ip, master_rpc_port, master_addresses)
        tserver_rpc_port = self.configs.saved_data.get("tserver_rpc_port")
        certs_dir = self.configs.saved_data.get("certs_dir")
        was_already_setup = self.configs.saved_data.get("cluster_member", False)

        common_gflags = [
            "--stop_on_parent_termination",
            "--undefok=stop_on_parent_termination",
            "--fs_data_dirs={}".format(self.configs.saved_data.get("data_dir")),
            "--webserver_interface={}".format(bind_ip),
            "--metrics_snapshotter_tserver_metrics_whitelist={}".format(
                ",".join(METRICS_SNAPSHOT_LIST)),
            "--yb_num_shards_per_tserver={}".format(YB_NUM_SHARDS_PER_TSERVER),
            "--ysql_num_shards_per_tserver={}".format(YSQL_NUM_SHARDS_PER_TSERVER),
            "--placement_cloud={}".format(self.configs.saved_data.get("cloud_provider")),
            "--placement_region={}".format(self.configs.saved_data.get("cloud_region")),
            "--placement_zone={}".format(self.configs.saved_data.get("cloud_zone")),
        ]

        if fault_tolerance == "region":
            common_gflags.append("--leader_failure_max_missed_heartbeat_periods=10")

        if self.configs.saved_data.get("secure"):
            common_gflags.extend(["--certs_dir={}".format(certs_dir),
            "--allow_insecure_connections=false",
            "--use_node_to_node_encryption=true",])

        yb_master_cmd = [find_binary_location("yb-master")] + \
            common_gflags + \
            [
                "--rpc_bind_addresses={}:{}".format(bind_ip, master_rpc_port),
                "--server_broadcast_addresses={}:{}".format(advertise_ip, master_rpc_port),
                "--replication_factor=1",
                "--use_initial_sys_catalog_snapshot",
                "--server_dump_info_path={}".format(
                    os.path.join(self.configs.saved_data.get("data_dir"), "master-info")),
                "--master_enable_metrics_snapshotter=true",
                "--webserver_port={}".format(self.configs.saved_data.get("master_webserver_port")),
                "--default_memory_limit_to_ram_ratio=0.35",
                "--instance_uuid_override={}".format(self.configs.saved_data.get("master_uuid")),
            ]
        # if a join ip is specified, bring up a shell mode master
        if not join_ip:
            yb_master_cmd.append("--master_addresses={}".format(master_addresses))
            yb_master_cmd.append("--cluster_uuid={}".format(
                self.configs.saved_data.get("universe_uuid")))

        if self.configs.saved_data.get("master_flags"):
            yb_master_cmd.extend(
                ["--{}".format(flag) for flag in \
                    self.configs.saved_data.get("master_flags").split(",")])

        yb_tserver_cmd = [find_binary_location("yb-tserver")] + common_gflags + \
            [
                "--{}={}".format(TS_MASTER_ADDRS_FLAG, master_addresses),
                "--rpc_bind_addresses={}:{}".format(bind_ip, tserver_rpc_port),
                "--server_broadcast_addresses={}:{}".format(advertise_ip, tserver_rpc_port),
                "--cql_proxy_bind_address={}:{}".format(
                    bind_ip, self.configs.saved_data.get("ycql_port")),
                "--server_dump_info_path={}".format(
                    os.path.join(self.configs.saved_data.get("data_dir"), "tserver-info")),
                "--start_pgsql_proxy", "--pgsql_proxy_bind_address={}:{}".format(
                    bind_ip, self.configs.saved_data.get("ysql_port")),
                "--tserver_enable_metrics_snapshotter=true",
                "--metrics_snapshotter_interval_ms=11000",
                "--webserver_port={}".format(self.configs.saved_data.get("tserver_webserver_port")),
                "--default_memory_limit_to_ram_ratio=0.6",
                "--instance_uuid_override={}".format(self.configs.saved_data.get("tserver_uuid")),
                "--start_redis_proxy=false",
            ]

        tserver_flags = self.configs.saved_data.get("tserver_flags")

        # If ysql_hba_conf_csv is present
        # Extract the value of ysql_hba_conf_csv
        # Remove the flag present in the tserver_flags string
        if tserver_flags.find("ysql_hba_conf_csv") != -1:
            ysql_hba_conf_csv_start_index = tserver_flags.find('ysql_hba_conf_csv')
            ysql_hba_conf_csv_end_index = tserver_flags.find('}', ysql_hba_conf_csv_start_index) + 1
            ysql_hba_conf_csv_flag = tserver_flags[ysql_hba_conf_csv_start_index:\
                    ysql_hba_conf_csv_end_index]
            ysql_hba_conf_csv_flag = ysql_hba_conf_csv_flag[ysql_hba_conf_csv_flag.find("{")+1:-1]

            # If the value was given through the config file
            # remove the starting and ending quotes.
            if ysql_hba_conf_csv_flag[0] == "'" and ysql_hba_conf_csv_flag[-1] == "'":
                ysql_hba_conf_csv_flag = ysql_hba_conf_csv_flag[1:-1]
            elif ysql_hba_conf_csv_flag[0] == '"' and ysql_hba_conf_csv_flag[-1] == '"':
                ysql_hba_conf_csv_flag = ysql_hba_conf_csv_flag[1:-1]

            # Remove the flag present in tserver_flags
            if ysql_hba_conf_csv_start_index == 0:
                tserver_flags = tserver_flags[ysql_hba_conf_csv_end_index+1:]
            else:
                tserver_flags = tserver_flags[:ysql_hba_conf_csv_start_index-1] + \
                    tserver_flags[ysql_hba_conf_csv_end_index:]

            yb_tserver_cmd.extend(["--ysql_hba_conf_csv={}".format(ysql_hba_conf_csv_flag)])

        # If ysql_pg_conf_csv is present
        # Extract the value of ysql_pg_conf_csv given through CLI
        # Remove the flag present in the tserver_flags string
        if tserver_flags.find("ysql_pg_conf_csv") != -1:
            ysql_pg_conf_csv_start_index = tserver_flags.find('ysql_pg_conf_csv')
            ysql_pg_conf_csv_end_index = tserver_flags.find('}', ysql_pg_conf_csv_start_index) + 1
            ysql_pg_conf_csv_flag = tserver_flags[ysql_pg_conf_csv_start_index:\
                    ysql_pg_conf_csv_end_index]
            ysql_pg_conf_csv_flag = ysql_pg_conf_csv_flag[ysql_pg_conf_csv_flag.find("{")+1:-1]

            # If the value was given through the config file
            # remove the starting and ending quotes.
            if ysql_pg_conf_csv_flag[0] == "'" and ysql_pg_conf_csv_flag[-1] == "'":
                ysql_pg_conf_csv_flag = ysql_pg_conf_csv_flag[1:-1]
            elif ysql_pg_conf_csv_flag[0] == '"' and ysql_pg_conf_csv_flag[-1] == '"':
                ysql_pg_conf_csv_flag = ysql_pg_conf_csv_flag[1:-1]

            # Remove the flag present in tserver_flags
            if ysql_pg_conf_csv_start_index == 0:
                tserver_flags = tserver_flags[ysql_pg_conf_csv_end_index+1:]
            else:
                tserver_flags = tserver_flags[:ysql_pg_conf_csv_start_index-1] + \
                    tserver_flags[ysql_pg_conf_csv_end_index:]

            yb_tserver_cmd.extend(["--ysql_pg_conf_csv={}".format(ysql_pg_conf_csv_flag)])

        if tserver_flags:
            yb_tserver_cmd.extend(
                ["--{}".format(flag) for flag in tserver_flags.split(",")])

        # Add authentication flags in tserver
        if self.configs.saved_data.get("secure"):
            yb_tserver_cmd.extend(["--use_client_to_server_encryption=true",
                "--certs_for_client_dir={}".format(certs_dir),])

        if self.configs.saved_data.get("ysql_enable_auth"):
            yb_tserver_cmd.extend(["--ysql_enable_auth=true"])

        if self.configs.saved_data.get("use_cassandra_authentication"):
            yb_tserver_cmd.extend(["--use_cassandra_authentication=true"])

        if self.configs.saved_data.get("dns_enabled"):
            yb_tserver_cmd.extend(["--use_node_hostname_for_local_tserver=true"])

        self.processes = {
            "master": YBProcessManager(
                "master", yb_master_cmd, self.configs.saved_data.get("log_dir"),
                self.configs.saved_data.get("data_dir")),
            "tserver": YBProcessManager(
                "tserver", yb_tserver_cmd, self.configs.saved_data.get("log_dir"),
                self.configs.saved_data.get("data_dir")),
        }

        for p in self.processes.values():
            pid = p.get_pid()
            if pid:
                Output.print_out(
                    "{} is already running... Is there an existing {} process?".format(
                        p.name, SCRIPT_NAME))
                # Clear self.processes so kill_children() doesn't kill existing processes.
                self.processes = {}
                return

        is_first_run = True
        callhome_thread = None
        masters_list_update_thread = None
        self.stop_callhome = False
        while True:
            should_callhome = False

            is_first_install = is_first_run and not self.is_yb_initialized()

            # Create data directory.
            data_dir = self.configs.saved_data.get("data_dir")
            if not os.path.exists(data_dir):
                Output.log(
                    "Creating data directory {}.".format(data_dir))
                os.makedirs(data_dir)

            # Delete corrupted data dirs left from interrupting yb-master and yb-tserver startup.
            pid_file_name = os.path.basename(self.script.pidfile)
            data_dir_files = [ x for x in os.listdir(data_dir) if x != pid_file_name ]
            if is_first_install and data_dir_files:
                Output.print_and_log(
                    ("Found files {} in data dir {} from possibly failed initialization."
                    " Removing...").format(data_dir_files, data_dir))
                rmcontents(data_dir, exclude_names=[pid_file_name])

            # Start or initialize yb-master and yb-tserver.
            if is_first_run:
                # Output.init_animation("Running system checks...")
                warnings = []
                warning_help_msg=""
                ulimits_failed = self.script.set_rlimits(print_info=True)
                if ulimits_failed:
                    msg = "Failed to meet recommended settings. Ulimits too low - {}.\n".format(
                    ", ".join(ulimits_failed))
                    ulimit_warn_msg = msg + "Note {} will still run, although it may fail for " \
                        "larger workloads. For more info, see {}".format(SCRIPT_NAME, CONFIG_LINK)
                    self.alerts.append((ALERT_WARNING, ULIMIT_ERR_CODE, ulimit_warn_msg))

                prereqs_check_result = self.prereqs_check(ulimits=ulimits_failed)
                # Output.update_animation(msg=prereqs_check_result['msg'],
                #     status=prereqs_check_result['status'])
                if prereqs_check_result['status']==Output.ANIMATION_SUCCESS:
                    Output.print_out(prereqs_check_result['msg'])
                elif prereqs_check_result['status']==Output.ANIMATION_WARNING:
                    warnings.extend(prereqs_check_result['msg'][:-1])
                    warning_help_msg = prereqs_check_result['msg'][-1]
                elif prereqs_check_result['status']==Output.ANIMATION_FAIL:
                    Output.log(msg=prereqs_check_result['msg'],
                        level=logging.ERROR)

                Output.init_animation("Starting the YugabyteDB Processes...")

                self.post_install_yb()

                ret = self.start_first_master_tserver(master_addresses)
                if ret:
                    Output.update_animation("Database failed to start",
                        status=Output.ANIMATION_FAIL)
                    Output.log_error_and_exit(ret)

                Output.update_animation("YugabyteDB Started")

                if join_ip:
                    Output.print_and_log(Output.ANIMATION_SUCCESS +
                            " Node joined a running cluster with UUID {}"
                            .format(self.configs.saved_data.get("universe_uuid")))

                if self.configs.saved_data.get("secure"):
                    Output.init_animation("Enabling Encryption in Transit and " +
                        "Password Authentication...")
                    if not join_ip and not was_already_setup:
                        alphadigits = string.ascii_letters + string.digits
                        new_password = ''.join(PASSWORD_GENNERATOR(alphadigits) for i in range(12))
                        self.update_db_passwords(new_password)
                        self.create_password_file()
                    Output.update_animation("Encryption in Transit and " +
                        "Password Authentication enabled")
                else:
                    warnings.append("Cluster started in an insecure mode without " +
                        "authentication and encryption enabled. For non-production use only, " +
                        "not to be used without firewalls blocking the internet traffic.")

                # Persist the config after successful start
                self.configs.save_configs()
            else:
                for name in ("master", "tserver"):
                    process = self.processes.get(name)
                    process.remove_error_logs()
                    if not process.is_running():
                        Output.log(
                            "{} died unexpectedly. Restarting...".format(process.name),
                            logging.ERROR)
                        if name == "tserver":
                            self.update_tserver_master_addrs()
                        process.start()
                        should_callhome = True

            if is_first_run:
                if self.configs.saved_data.get("ui"):
                    yugabyted_ui_cmd = [ find_binary_location("yugabyted-ui")] + \
                        [
                            "-database_host={}".format(bind_ip)
                        ]
                    if self.configs.saved_data.get("secure"):
                        yugabyted_ui_cmd.extend(["-secure=true",
                            "-database_password={}".format(
                            self.configs.saved_data.get("database_password"))])

                    self.processes["yugabyted-ui"] = ProcessManager(
                        "yugabyted-ui", yugabyted_ui_cmd, self.configs.saved_data.get("log_dir"),
                        self.configs.saved_data.get("data_dir"))

            if self.configs.saved_data.get("ui"):
                (_, was_started) = self.verify_start_yugabyted_ui(is_first_run, is_first_install)
                should_callhome = should_callhome or was_started

            if is_first_install and not join_ip:
                self.first_install_init_auth()

            if warnings:
                warning_msg = "\n" + Output.make_yellow(Output.ANIMATION_WARNING +
                    " WARNINGS") + ":\n"

                for msg in warnings:
                    warning_msg += "- " + msg + "\n"
                if warning_help_msg:
                    warning_msg += warning_help_msg

            if is_first_run:
                status = self.get_status_string() + \
                    "{} YugabyteDB started successfully! To load a sample dataset, " \
                    "try '{} demo'.\n" \
                    "{} Join us on Slack at {}\n" \
                    "{} Claim your free t-shirt at {}\n".format(
                        Output.ROCKET, SCRIPT_NAME, Output.PARTY,
                        Output.make_underline(SLACK_LINK), Output.SHIRT,
                        Output.make_underline(COMMUNITY_REWARDS_LINK))

                if self.configs.saved_data.get("secure") and not join_ip:
                    status += "\n{} is stored at {}\n".format(Output.make_cyan("Credentials File"),
                    os.path.join(self.configs.saved_data.get("data_dir"),
                        "{}_credentials.txt".format(SCRIPT_NAME)))

                if len(self.setup_env_init.get_ysql_password()) > 99:
                    status = status + Output.make_red(YSQL_PASSWORD_LENGTH_WARNING)

                if warnings:
                    Output.print_out(warning_msg)

                Output.print_out(status)

                if self.configs.temp_data.get("background"):
                    # Let original process know daemon was successful so it can exit.
                    # This is to display the initial status message.
                    self.script.daemon_success.put(1)
                    # Ignore any console output as important information will be logged.
                    with open('/dev/null', 'r+') as dev_null:
                        Output.console_access = False
                        sys.stderr.flush()
                        sys.stdout.flush()
                        os.dup2(dev_null.fileno(), sys.stdin.fileno())
                        os.dup2(dev_null.fileno(), sys.stderr.fileno())
                        os.dup2(dev_null.fileno(), sys.stdout.fileno())

                Diagnostics.first_run_secs = time.time() - start_time_sec
                Diagnostics.first_install = is_first_install

                if self.configs.saved_data.get("callhome"):
                    callhome_thread = Thread(target=self.callhome_loop)
                    callhome_thread.daemon = True
                    callhome_thread.start()

                masters_list_update_thread = Thread(target=self.update_masters_list_loop)
                masters_list_update_thread.daemon = True
                masters_list_update_thread.start()

            is_first_run = False
            if should_callhome:
                self.callhome()

            time.sleep(int(self.configs.saved_data.get("polling_interval")))

        # Stop callhome. Useful in future if we do anything after quitting.
        self.stop_callhome = True
        callhome_thread.join()

    def verify_start_yugabyted_ui(self, is_first_run, is_first_install):

        was_started = False
        err = None

        if not self.configs.saved_data.get("ui"):
            return (err, was_started)

        yugabyted_ui_process = self.processes.get("yugabyted-ui")

        try:
            if is_first_run:
                Output.init_animation("Bringing up UI...")

            # Start yugabyted UI process.
            if not yugabyted_ui_process.is_running():
                if not is_first_run:
                    Output.log(
                        "Webserver died unexpectedly. Restarting...", logging.ERROR)
                yugabyted_ui_process.start()
                was_started = True

            # After first run, do not attempt any more setup, just return.
            if not is_first_run:
                return (err, was_started)

            if is_first_run:
                Output.update_animation("UI ready")

        finally:
            if is_first_run:
                animation_status = Output.ANIMATION_FAIL if err else Output.ANIMATION_SUCCESS
                # Output.update_animation("UI status", status=animation_status)
        return (err, was_started)

    # Returns (error string, yw_started).
    # yw_started is True if YW was actually started
    def maybe_start_yw(self, is_first_run, is_first_install):
        was_started = False
        err = None

        if not self.configs.saved_data.get("ui"):
            return (err, was_started)

        yw_process = self.processes.get("yugaware")
        yw_proxy = YugaWareProxy(self.advertise_ip(),
            self.configs.saved_data.get("webserver_port"))

        # Setup schema for play framework.
        if is_first_run and not self.is_yw_initialized():
            Output.log("Setting up admin console schema...")
            Output.init_animation("Preparing UI schema...")
            if not self.init_yw():
                #TODO: make this return to caller
                Output.log_error_and_exit("Failed to set up admin console schema...")

            Output.update_animation("UI schema ready")

        try:
            if is_first_run:
                Output.init_animation("Bringing up UI...")

            # Start YW process.
            if not yw_process.is_running():
                if not is_first_run:
                    Output.log(
                        "Webserver died unexpectedly. Restarting...", logging.ERROR)
                yw_process.start()
                was_started = True

            # After first run, do not attempt any more setup, just return.
            if not is_first_run:
                return (err, was_started)

            # Login with username/pwd, this tells us that YW server is up.
            err = self.wait_yw_login(yw_proxy, insecure=False)
            if err:
                return (err, was_started)

            # On first install run, always setup YW.
            # On a first run that is not first install,
            # check if setup still needs to complete.
            needs_setup = is_first_install
            if not needs_setup:
                # Login insecurely - if this fails, this likely means
                # YW wasn't fully setup the first time around.
                err = self.wait_yw_login(yw_proxy, insecure=True)
                if err:
                    Output.log("Unable to insecure login to YW: {}".format(err))
                    needs_setup = True

            if not needs_setup:
                return (err, was_started)

            # Set up login without username and password.
            err = yw_proxy.set_security("insecure")
            if err:
                return (err, was_started)

            # Verify login without username and password.
            err = yw_proxy.insecure_login()
            if err:
                return (err, was_started)
            yw_logged_in = True

            full_master_list = self.wait_get_all_masters(timeout=60)
            if not full_master_list:
                err = "Unable to find full master list for YW import"
                return (err, was_started)

            # Import the universe (or re-import it). Re-importing should be harmless.
            err = yw_proxy.import_universe(
                        ",".join(full_master_list),
                        self.master_port(),
                        self.configs.saved_data.get("universe_uuid"))
            if err:
                return (err, was_started)

            err = yw_proxy.set_landing_page(
                    self.configs.saved_data.get("universe_uuid"))
            if err:
                return (err, was_started)

            if is_first_run:
                Output.update_animation("UI ready")
            if is_first_run and yw_process.is_running() and self.alerts:
                yw_proxy.send_alerts(self.alerts)

        finally:
            if is_first_run:
                animation_status = Output.ANIMATION_FAIL if err else Output.ANIMATION_SUCCESS
                Output.update_animation("UI status", status=animation_status)
        return (err, was_started)

    # Pushes yugabyted script to background as a daemon. The process is not tied to a shell, but
    # it will not survive between machine restarts.
    def daemonize(self):
        def remove_handlers():
            if PY_VERSION < 3:
                handlers = [e for e in atexit._exithandlers if e[0] == self.kill_children]
                for handler in handlers:
                    atexit._exithandlers.remove(handler)
            else:
                atexit.unregister(self.kill_children)

        if os.fork():
            # Delete any custom exit handlers so daemon has full control.
            remove_handlers()

            # If parent is interrupted, kill the children as well. Note there is potentially a
            # window where the daemon hasn't created its pidfile yet and this will error out before
            # it can kill the daemon.
            self.set_signals(self.stop)

            # Keep the parent process alive until the daemon confirms yugabyted started properly.
            try:
                self.script.daemon_success.get(timeout=600)
            except queue.Empty as e:
                Output.print_and_log(
                    "Timed out trying to start {} daemon.".format(SCRIPT_NAME), logging.ERROR)
                self.stop()
            sys.exit()
        os.chdir(YUGABYTE_DIR)
        os.setsid()
        os.umask(0)
        if os.fork():
            remove_handlers()
            sys.exit()
        Output.log("Daemon grandchild process begins execution.")

    # Sets env variables needed for yugabyted start.
    def set_env_vars(self):
        # Sets YW metrics to use local database.
        os.environ["USE_NATIVE_METRICS"] = "true"

    # Runs post_install script for linux computers.
    def post_install_yb(self):
        if not sys.platform.startswith('linux'):
            return

        post_install_script_path = find_binary_location('post_install.sh')

        # If post_install.sh script is not found then we assume that
        # we are executing it in development mode, hence skip post_install.sh script
        # TODO(Sanket): Refactor the design to have yugabyted a way of knowing whether it
        # is an install env v/s dev
        if(post_install_script_path is None):
            return

        Output.log("Running the post-installation script {} (may be a no-op)".format(
                    post_install_script_path))
        process = subprocess.Popen(
                post_install_script_path, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        std_out, std_err = process.communicate()
        if process.returncode != 0:
            Output.log_error_and_exit(
                "Failed running {} (exit code: {}). Standard output:\n{}\n. "
                "Standard error:\n{}".format(
                    post_install_script_path, process.returncode, std_out, std_err))
        Output.log("Successfully ran the post-installation script.")


    # Initialize YW process. Creates all necessary tables. Returns false if init failed.
    def init_yw(self):
        # Create Play evolutions table. Required for YugaWare to start up properly.
        create_play_table = [
            os.path.join(YUGAWARE_BIN_DIR, "yugaware"),
            "-Dconfig.file=" + YUGAWARE_CONF,
            "-Dlog.override.path={}".format(self.configs.saved_data.get("log_dir"))
        ]
        Output.log("Initializing play tables...")
        run_process(create_play_table)
        Output.log("Done initializing play tables.")

        return True

    # Returns if yb-master and yb-tserver were properly initialized before.
    def is_yb_initialized(self):
        for info_file in ("master-info", "tserver-info", "tserver-info-cql"):
            if not os.path.exists(os.path.join(self.configs.saved_data.get("data_dir"), info_file)):
                return False
        return True

    # Returns if yugaware was properly initialized before.
    def is_yw_initialized(self):
        # Check Play evolutions table was created.
        Output.log("Checking play_evolutions table")
        list_tables_cmd = [find_binary_location("ysqlsh"), "-d", WEBSERVER_DB, "-c", "\d"]
        out, err, ret_code = run_process(list_tables_cmd)
        Output.log("Finished checking play evolutions table")
        return not err and not ret_code and "play_evolutions" in out

    # Returns true if this master was found in the current list of masters
    def wait_master(self, master_addr):

        if (not self.processes.get("master").is_running()):
            Output.log("Failed waiting for yb-master... process died.", logging.ERROR)
            raise RuntimeError("process died unexpectedly.")

        cur_master_uuids = [ m[0] for m in YBAdminProxy.get_masters(master_addr) ]
        master_uuid = self.configs.saved_data.get("master_uuid")
        if not cur_master_uuids:
            raise RetryableError()
        return master_uuid in cur_master_uuids

    # Returns the current list of master UUIDs
    def get_master_uuids(self, master_addr):

        if (not self.processes.get("master").is_running()):
            Output.log("Failed waiting for yb-master... process died.", logging.ERROR)
            raise RuntimeError("process died unexpectedly.")

        cur_master_uuids = [ m[0] for m in YBAdminProxy.get_masters(master_addr) ]
        if not cur_master_uuids:
            raise RetryableError()
        return cur_master_uuids

    # Use the masters we know (ourselves and the join target) to discover the full cluster.
    # Retry until timeout in case the masters we know are still coming up.
    def wait_get_all_masters(self, timeout=180):
        Output.log("Waiting to get the full master addrs list from master")
        try:
            return retry_op(self.get_all_masters, timeout)
        except RuntimeError:
            Output.log("Failed to query for all masters. Exception: {}".format(
                traceback.format_exc()))
            return False

    # Use the masters we know (ourselves and the join target) to discover the full cluster.
    def get_all_masters(self):

        current_masters = self.configs.saved_data.get("current_masters")

        if current_masters:
            all_masters = [ m[1] for m in YBAdminProxy.get_masters(current_masters) ]
            Output.log("Got all masters: {}".format(all_masters))
            if all_masters:
                return all_masters

        join_ip = self.configs.saved_data.get("join")
        advertise_ip = self.advertise_ip()
        all_masters = None
        for master_ip in (join_ip, advertise_ip):
            if not master_ip:
                continue
            master_addr = "{}:{}".format(master_ip,
                                        self.configs.saved_data.get("master_rpc_port"))
            all_masters = [ m[1] for m in YBAdminProxy.get_masters(master_addr) ]
            Output.log("Got all masters: {}".format(all_masters))
            if all_masters:
                return all_masters

        raise RetryableError()


    # Waits till the newly added master comes in the list of masters of cluster
    def wait_get_master(self, master, timeout=180):
        Output.log("Waiting for master with address {} to be added".format(master))
        try:
            return retry_op_with_argument(self.get_master_at_addrs, master, timeout)
        except RuntimeError:
            Output.log("Failed to find master {} in the masters list. Exception: {}".format(
                traceback.format_exc()))
            return False

    # Raises a Retryable error if the master is not in the list of master of the cluster
    def get_master_at_addrs(self, master):

        current_masters = self.configs.saved_data.get("current_masters")
        all_masters_and_roles = ""
        if current_masters:
            all_masters_and_roles = { m[1].split(":")[0]: m[2]
                                    for m in YBAdminProxy.get_masters(current_masters) }
        if not all_masters_and_roles:
            join_ip = self.configs.saved_data.get("join")
            advertise_ip = self.advertise_ip()
            master_addr = "{}:{}".format(join_ip if join_ip else advertise_ip,
                                            self.configs.saved_data.get("master_rpc_port"))
            all_masters_and_roles = { m[1].split(":")[0]: m[2]
                                        for m in YBAdminProxy.get_masters(master_addr) }

        if master in all_masters_and_roles and all_masters_and_roles[master] == "FOLLOWER":
            return True

        raise RetryableError()

    # Get the current list of masters known to a tserver using api/v1/masters endpoint
    # of the tserver. Use the node address given with the --join flag or use the
    # advertise address if join flag is not provided.
    def get_current_masters_from_api(self, tserverIp):
        tserver_addr = "{}:{}".format(tserverIp,
                            self.configs.saved_data.get("tserver_webserver_port"))
        try:
            tserverMastersAPI = "http://{}/api/v1/masters".format(tserver_addr)
            response = urlopen(Request(tserverMastersAPI))
            jsonResponseFromTserver = json.load(response)
            dictOfAllNodes = jsonResponseFromTserver.get("master_server_and_type")

            currentMastersCSV = ""
            lenOfMasters = len(dictOfAllNodes)
            for node in dictOfAllNodes:
                currentMastersCSV += node["master_server"]
                lenOfMasters -= 1
                if lenOfMasters > 0:
                    currentMastersCSV += ","

            Output.log("Tserver {} returned the following ".format(tserverIp) +
                "set of the current masters {}.".format(currentMastersCSV),
                    logging.DEBUG)

            return currentMastersCSV

        except HTTPError as http_err:
            Output.log('HTTP error occurred while fetching current' +
                    'masters from tserver: {}', http_err)
            return ''
        except Exception as err:
            Output.log('Other error occurred while fetching current' +
                    'masters from tserver: {}', err)
            return ''

    # Get the current master leader known to a tserver using api/v1/masters endpoint
    # of the tserver. Use the node address given with the --join flag or use the
    # advertise address if join flag is not provided.
    def get_current_master_leader_from_api(self):

        join_ip = self.configs.saved_data.get("join")
        advertise_ip = self.advertise_ip()
        tserver_addr = "{}:{}".format(join_ip if join_ip else advertise_ip,
                                        self.configs.saved_data.get("tserver_webserver_port"))

        try:
            tserverMastersAPI = "http://{}/api/v1/masters".format(tserver_addr)
            response = urlopen(Request(tserverMastersAPI))
            jsonResponseFromTserver = json.load(response)
            dictOfAllNodes = jsonResponseFromTserver.get("master_server_and_type")

            masterLeader = ""
            for node in dictOfAllNodes:
                if node["is_leader"]:
                    masterLeader = node["master_server"]
                    break

            Output.log("Tserver {} returned the following".format(tserver_addr) +
                        "master leader {}.".format(masterLeader),
                            logging.DEBUG)

            return masterLeader

        except HTTPError as http_err:
            print('HTTP error occurred while fetching cloud location: {}', http_err)
            return ''
        except Exception as err:
            print('Other error occurred while fetching cloud location: {}', err)
            return ''

    # Waits till the newly removed master doesn't comes in the list of masters of cluster
    def wait_remove_master(self, master, timeout=180):
        Output.log("Waiting for master with address {} to be removed".format(master))
        try:
            return retry_op_with_argument(self.remove_master_at_addrs, master, timeout)
        except RuntimeError:
            Output.log("Newly removed master {} is still present in the masters list." +
                    " Exception: {}".format(traceback.format_exc()))
            return False

    # Raises a Retryable error if the newly removed master is in the list of master of the cluster
    def remove_master_at_addrs(self, master):
        join_ip = self.configs.saved_data.get("join")
        advertise_ip = self.advertise_ip()
        master_addr = "{}:{}".format(join_ip if join_ip else advertise_ip,
                                        self.configs.saved_data.get("master_rpc_port"))

        all_masters = [ m[1].split(":")[0] for m in YBAdminProxy.get_masters(master_addr) ]
        if master not in all_masters:
            return True

        raise RetryableError()

    # Get Leader master of the cluster
    def get_leader_master(self):

        current_masters = self.configs.saved_data.get("current_masters")
        if current_masters:
            all_masters_info = YBAdminProxy.get_masters(current_masters)
            for master_info in all_masters_info:
                if master_info[2] == "LEADER":
                    return master_info[1]

        join_ip = self.configs.saved_data.get("join")
        advertise_ip = self.advertise_ip()
        master_addr = "{}:{}".format(join_ip if join_ip else advertise_ip,
                                        self.configs.saved_data.get("master_rpc_port"))
        all_masters_info = YBAdminProxy.get_masters(master_addr)
        for master_info in all_masters_info:
            if master_info[2] == "LEADER":
                return master_info[1]

        Output.log_error_and_exit("Couldn't get Leader master")

    # Get all masters placement locations
    def get_all_masters_locations(self, master_hostport):

        try:
            leaderMasterURL = "http://{}/api/v1/tablet-servers".format(master_hostport)
            response = urlopen(Request(leaderMasterURL))
            jsonResponseFromMaster = json.load(response)
            dictOfAllNodes = jsonResponseFromMaster.get("")

            placementInfoOfEveryNode = {}
            for node in dictOfAllNodes:
                hostname = node.split(":")[0]
                cloudLocationOfHost = "{}.{}.{}".format(dictOfAllNodes[node]["cloud"],
                    dictOfAllNodes[node]["region"], dictOfAllNodes[node]["zone"])
                placementInfoOfEveryNode[hostname] = cloudLocationOfHost

            return placementInfoOfEveryNode

        except HTTPError as http_err:
            print('HTTP error occurred while fetching cloud location: {}', http_err)
        except Exception as err:
            print('Other error occurred while fetching cloud location: {}', err)

    # Get the location of a master in accordance to the fault tolerance
    def get_cloud_location_per_fault_tolerance(self, master_location):
        fault_tolerance = self.configs.temp_data.get("fault_tolerance")
        master_location = master_location.split(".")
        ft_location = ""
        if fault_tolerance == "cloud":
            ft_location = master_location[0]
        elif fault_tolerance == "region":
            ft_location = ".".join(master_location[:2])
        else:
            ft_location = ".".join(master_location)

        return ft_location

    # Get new valid master addresses that does not violate fault tolerance policy
    def get_new_valid_masters(self, current_masters, leader_master,
                              master_locations):

        replication_factor = int(self.configs.temp_data.get("replication_factor"))
        # ft_locations_to_masters_map is map in the form of {ft_location: list_of_masters}.
        # Here ft_location means the fault tolerance location (cloud.region for ft=region and
        # cloud.region.zone for ft=zone).
        # list_of_masters is the list of all the masters present in that ft_location.
        # This map is used to equally distribute the nodes if the number of ft_locations
        # is less than the replication factor (implied or explicit) specified in the
        # configure command.
        ft_locations_to_masters_map = dict()
        for master, location in master_locations.items():
            ft_location = self.get_cloud_location_per_fault_tolerance(location)
            if ft_location not in ft_locations_to_masters_map.keys():
                ft_locations_to_masters_map[ft_location] = [master]
            else:
                ft_locations_to_masters_map[ft_location].append(master)

        new_master_locations = dict()
        ft_location_of_leader_master = self.get_cloud_location_per_fault_tolerance(
                                                master_locations[leader_master])
        new_master_locations[leader_master] = ft_location_of_leader_master
        ft_locations_to_masters_map[ft_location_of_leader_master].remove(leader_master)
        # check if the current master's cloud location are already
        # statisfying the fault tolerance value and replication factor (implied or explicit)
        # specified in the configure command
        for master in current_masters:
            ft_location = self.get_cloud_location_per_fault_tolerance(master_locations[master])
            if ft_location not in new_master_locations.values():
                new_master_locations[master] = ft_location
                ft_locations_to_masters_map[ft_location].remove(master)

        if len(new_master_locations) == replication_factor:
            return list(new_master_locations.keys())

        # if new masters list is not equal to replication factor,
        # determine new masters based on the distinct cloud locations
        # of nodes in the cluster
        for master, location in master_locations.items():
            ft_location = self.get_cloud_location_per_fault_tolerance(location)
            if ft_location not in new_master_locations.values():
                new_master_locations[master] = ft_location
                ft_locations_to_masters_map[ft_location].remove(master)
            if len(new_master_locations) == replication_factor:
                return list(new_master_locations.keys())

        # if new master list is not equal to replication factor after iterating
        # through the distinct cloud locations, add the existing masters back
        # to the new master's list for satisfying the replication factor.
        new_valid_masters_list = list(new_master_locations.keys())
        while len(new_valid_masters_list) != replication_factor:
            for location, master_list in ft_locations_to_masters_map.items():
                if len(master_list) != 0:
                    new_valid_masters_list.append(master_list.pop())
                if len(new_valid_masters_list) == replication_factor:
                    break

        return new_valid_masters_list

    # Replace the old master with a new one to maintain fault tolerance policy
    def replace_master(self, master_addr, old_master, new_master):
        self.add_master_for_data_placement(master_addr, new_master)
        self.remove_master_for_data_placement(master_addr, old_master)

    # add a new master computed during configure data_placement command
    def add_master_for_data_placement(self, master_addr, new_master):

        Output.log("Adding master {} to the cluster.".format(new_master))
        if not YBAdminProxy.add_master(master_addr, new_master):
            Output.log_error_and_exit("Failed to add master {} to the cluster."
                            .format(new_master))
        if not self.wait_get_master(new_master):
            Output.log_error_and_exit("Couldn't get master {} in the cluster masters list."
                            .format(new_master))
        else:
            Output.log("Added master {} to the cluster".format(new_master))

    # remove an master computed during configure data_placement command
    def remove_master_for_data_placement(self, master_addr, old_master):

        Output.log("Removing master {} from the cluster.".format(old_master))
        if not YBAdminProxy.remove_master(master_addr, old_master):
            Output.log_error_and_exit("Failed to remove master {} from the cluster."
                            .format(old_master))
        if not self.wait_remove_master(old_master):
            Output.log_error_and_exit("master {} in the cluster masters list still exists."
                            .format(old_master))
        else:
            Output.log("Removed master {} from the cluster".format(old_master))


    # Get status details to print after configure data_placement was run
    def get_configure_status_details(self, placement_locations, new_masters):

        fault_tolerance = self.configs.temp_data.get("fault_tolerance")
        replication_factor = int(self.configs.temp_data.get("replication_factor"))

        # Get the number of nodes present in each AZ/region
        placement_location_map = dict()
        for master in new_masters:
            ft_location = self.get_cloud_location_per_fault_tolerance(placement_locations[master])
            if ft_location not in placement_location_map.keys():
                placement_location_map[ft_location] = 1
            else:
                placement_location_map[ft_location] += 1

        status_details = []
        status_display_info = {}

        # Case Scenario: When each AZ/region has only 1 node. (Most happy path)
        if len(placement_location_map) == replication_factor:
            final_status = ""
            ft_status = ""

            # Case Scenario: When rf = 1, the universe cannot survive the failure of the
            # AZ/region in which the master node is located.
            if replication_factor == 1:
                if fault_tolerance == "zone":
                    final_status = "Configuration successful."
                    ft_status = "Universe cannot survive even 1 availability zone failure"
                elif fault_tolerance == "region":
                    final_status = "Configuration successful. Primary data placement is " + \
                        "not geo-redundant."
                    ft_status = "Universe cannot survive even 1 region failure."

                status_details = [
                    (Output.make_yellow("Status"), final_status),
                    (Output.make_yellow("Fault Tolerance"), ft_status),
                ]
                status_display_info[ft_status] = Output.make_red

            # Case Scenario: When rf = 3, 5, 7. the universe can survive atmost (rf-1)/2
            # AZ/region failure
            else:
                if fault_tolerance == "zone":
                    final_status = "Configuration successful."
                    ft_status = "Universe can survive at most any " + \
                        "{} availability zone failure".format(replication_factor//2)
                elif fault_tolerance == "region":
                    final_status = "Configuration successful. Primary data placement is " + \
                        "geo-redundant."
                    ft_status = "Universe can survive at most any " + \
                        "{} region failure.".format(replication_factor//2)

                status_details = [
                    (Output.make_yellow("Status"), final_status),
                    (Output.make_yellow("Fault Tolerance"), ft_status),
                ]
                status_display_info[ft_status] = Output.make_green

        # Case Scenario: When all the master nodes belong to the same AZ/region
        # In this case, the universe cannot survive even 1 AZ/region failure.
        elif len(placement_location_map) == 1:
            final_status = ""
            ft_status = ""

            if fault_tolerance == "zone":
                final_status = "Configuration successful."
                ft_status = "Universe cannot survive even 1 availability zone failure."
            elif fault_tolerance == "region":
                final_status = "Configuration successful. Primary data placement is " + \
                    "not geo-redundant."
                ft_status = "Universe cannot survive even 1 region failure."

            status_details = [
                (Output.make_yellow("Status"), final_status),
                (Output.make_yellow("Fault Tolerance"), ft_status)
            ]
            status_display_info[ft_status] = Output.make_red

        # Case Scenario: When all master nodes are distributed accross 2 AZs/regions
        # In this case the universe can survive failure of only
        # 1 AZ/region (The one with lower number of master nodes).
        elif len(placement_location_map) == 2:
            number_of_failure_node_tolerance = replication_factor//2
            if fault_tolerance == "zone":
                final_status = "Configuration successful."
                ft_status = [
                    "For specified Replication factor (rf) {},".format(replication_factor) + \
                        " not enough availability zones.",
                    "Universe can survive the failure of only {} availability zone.".format(
                        [k for k, v in placement_location_map.items()
                            if v<=number_of_failure_node_tolerance][0]),
                    "Following are number of nodes in each availability zone."
                ]
            elif fault_tolerance == "region":
                final_status = "Configuration successful. Primary data placement is " + \
                    "not geo-redundant."
                ft_status = [
                    "For specified Replication factor (rf) {},".format(replication_factor) + \
                        " not enough regions.",
                    "Universe can survive the failure of only {} region.".format(
                        [k for k, v in placement_location_map.items()
                            if v<=number_of_failure_node_tolerance][0]),
                    "Following are number of nodes in each region."
                ]

            status_details = [
                (Output.make_yellow("Status"), final_status),
                (Output.make_yellow("Fault Tolerance"), ft_status[0]),
                (Output.make_yellow(""), ft_status[1]),
                (Output.make_yellow(""), ft_status[2]),
            ]
            status_display_info[ft_status[0]] = Output.make_yellow
            status_display_info[ft_status[1]] = Output.make_yellow

            for az, nodes in sorted(placement_location_map.items(), key=lambda x: x[1],
                                                                        reverse=True):
                az_node_info = "{} : {}".format(az, nodes)
                status_details += [
                    (Output.make_yellow(""), az_node_info)
                ]
                if nodes > replication_factor//2:
                    status_display_info[az_node_info] = Output.make_red
                else:
                    status_display_info[az_node_info] = Output.make_green

        # Case Scenario: When all master nodes are distributed accross more than 2 AZs/regions
        else:
            final_status = ""
            ft_status = ""
            if fault_tolerance == "zone":
                final_status = "Configuration successful."
                ft_status = [
                    "For specified Replication factor (rf) {},".format(replication_factor) + \
                        " not enough availability zones.",
                    "Universe can survive the failure of availability zones,",
                    "if the total number of down nodes in the YugabyteDB cluster doesn't " + \
                        "exceed {}.".format(replication_factor//2),
                    "Following are number of nodes in each availability zone."
                ]
            elif fault_tolerance == "region":
                final_status = "Configuration successful. Primary data placement is " + \
                    "not geo-redundant."
                ft_status = [
                    "For specified Replication factor (rf) {},".format(replication_factor) + \
                        " not enough regions.",
                    "Universe can survive the failure of regions,",
                    "if the total number of down nodes in the YugabyteDB cluster doesn't " + \
                        "exceed {}.".format(replication_factor//2),
                    "Following are number of nodes in each region."
                ]

            status_details += [
                (Output.make_yellow("Status"), final_status),
                (Output.make_yellow("Fault Tolerance"), ft_status[0]),
                (Output.make_yellow(""), ft_status[1]),
                (Output.make_yellow(""), ft_status[2]),
                (Output.make_yellow(""), ft_status[3]),
            ]
            status_display_info[ft_status[0]] = Output.make_yellow
            status_display_info[ft_status[1]] = Output.make_yellow
            status_display_info[ft_status[2]] = Output.make_yellow

            for az, nodes in sorted(placement_location_map.items(), key=lambda x: x[1],
                                    reverse=True):
                az_node_info = "{} : {}".format(az, nodes)
                status_details += [
                    (Output.make_yellow(""), az_node_info)
                ]

        status_display_info = None if len(status_display_info) == 0 else status_display_info

        return [status_details, status_display_info]

    # This functions is used to determine if the placement constraint specified in
    # configure command is valid
    def is_placement_constraint_valid_values(self, placement_locations, placement_constraint):

        placement_constraint_list = placement_constraint.split(',')
        placement_locations_list = placement_locations.values()
        for constraint in placement_constraint_list:
            if constraint in placement_locations_list:
                is_valid = True
            else:
                is_valid = False
                break

        return is_valid

    def is_placement_constraint_valid_length(self, placement_constraint):

        replication_factor = int(self.configs.temp_data.get("replication_factor"))
        placement_constraint_list = placement_constraint.split(',')
        is_valid = True
        if len(placement_constraint_list) != replication_factor:
            is_valid = False

        return is_valid

    # Updating the database user passwords for postgres and cassandra
    def update_db_passwords(self, new_password):
        ysql_proxy = YsqlProxy(self.advertise_ip(), self.configs.saved_data.get("ysql_port"))
        Output.log("Attempting to update Postgres password.")
        try:
            retry_op_with_argument(ysql_proxy.try_update_password, new_password, timeout=60)
        except RuntimeError:
            Output.log_error_and_exit("Could not update Postgress user password." +
                " Exception: {}".format(traceback.format_exc()))

        self.setup_env_init.setup_cert_file_path(self.configs.saved_data.get("ca_cert_file_path"))
        ycql_proxy = YcqlProxy(self.advertise_ip(), self.configs.saved_data.get("ycql_port"),
                        secure=self.configs.saved_data.get("secure"))
        Output.log("Attempting to update Cassandra password.")
        try:
            retry_op_with_argument(ycql_proxy.try_update_password, new_password, timeout=60)
        except RuntimeError:
            Output.log_error_and_exit("Could not update Cassandra user password." +
                " Exception: {}".format(traceback.format_exc()))

        self.setup_env_init.update_passwords(new_password)
        self.configs.saved_data["database_password"] = new_password

    # Create a new file in base directory and put Ysql login credentials in it.
    def create_password_file(self):
        password_file = os.path.join(self.configs.saved_data.get("data_dir"),
                "{}_credentials.txt".format(SCRIPT_NAME))

        ysql_username, ysql_password, ysql_db = self.setup_env_init.get_ysql_credentials()
        ycql_username, ycql_password, ycql_keyspace = self.setup_env_init.get_ycql_credentials()

        content = ""
        content += "YSQL Credentials:\nUsername: {}\nPassword: {}\n" \
            "Database: {}\n\n".format(ysql_username, ysql_password, ysql_db)
        content += "YCQL Credentials:\nUsername: {}\nPassword: {}\n" \
            "Keyspace: {}\n".format(ycql_username, ycql_password, ycql_keyspace)

        with open(password_file, "w+") as f:
            f.write(content)

    # When the 3rd node joins, this method will set the placement location and rf to 3
    def setup_first_cluster_config(self):
        leader_master = self.get_leader_master().split(':')[0]
        leader_master_http_endpoint = "{}:{}".format(leader_master,
                        self.configs.saved_data.get("master_webserver_port"))

        placement_locations = self.get_all_masters_locations(leader_master_http_endpoint)
        placement_info = list(placement_locations.values())
        placement_info.append("{}.{}.{}".format(self.configs.saved_data.get("cloud_provider"),
                                                self.configs.saved_data.get("cloud_region"),
                                                self.configs.saved_data.get("cloud_zone")))
        placement_info = ",".join(placement_info)

        master_addresses = list(placement_locations.keys())
        master_addresses.append(self.configs.saved_data.get("advertise_address"))
        master_addresses = ["{}:{}".format(master, self.configs.saved_data.get("master_rpc_port")) \
                                           for master in master_addresses]
        master_addresses = ",".join(master_addresses)

        if not YBAdminProxy.modify_placement_info(master_addresses, placement_info):
            Output.log_error_and_exit(Output.make_red("FAILED") + ": Setting of default " +
                                      "data placement policy on the cluster.")

    # Verify that the master is in the current list of masters.
    # If not, set it up appropriately.
    def setup_master(self, timeout=180):
        Output.log("Waiting for master")
        join_ip = self.configs.saved_data.get("join")
        master_addrs = self.get_current_masters_from_api(join_ip)
        # API didn't return any masters addresses, use join or advertise address
        if not master_addrs:
            join_ip = self.configs.saved_data.get("join")
            master_ip = join_ip if join_ip else self.advertise_ip()
            master_addrs = "{}:{}".format(master_ip,
                                        self.configs.saved_data.get("master_rpc_port"))

        # save the current known masters received from the get_current_masters_from_api()
        self.configs.saved_data["current_masters"]= master_addrs

        try:
            master_uuids = retry_op_with_argument(self.get_master_uuids, master_addrs)
            current_node_master_uuid = self.configs.saved_data.get("master_uuid")
            # If False, it means the master is
            # not part of the current set of masters. If we have a
            # join_ip, let's try to add ourselves to it, otherwise
            # it is a hard failure.
            if current_node_master_uuid in master_uuids:
                self.configs.saved_data["cluster_member"] = True
                return True
            if not join_ip:
                return False
        except RuntimeError:
            Output.log_error_and_exit("Failed to setup master. Exception: {}".format(
                traceback.format_exc()))
            return False

        # The master was not in the current list of masters
        # and we have a valid join_ip

        bind_ip = self.configs.saved_data.get("advertise_address")
        # master_addrs = "{}:{}".format(join_ip,
        #             self.configs.saved_data.get("master_rpc_port"))
        # master_uuids = [ m[0] for m in YBAdminProxy.get_masters(master_addrs) ]

        if len(master_uuids) >= 3:
            # this is going to be a standalone shell master
            return True
        if not YBAdminProxy.add_master(master_addrs, bind_ip):
            Output.log_error_and_exit("Unable to add master {} to existing cluster at {}.".format(
                bind_ip, join_ip))
            return False

        # If we are the third master, set replication factor to 3. This makes the cluster
        # automatically expand to rf3 when the third node is added.
        if len(master_uuids) == 2:
            self.setup_first_cluster_config()

        try:
            if retry_op_with_argument(self.get_master_uuids, master_addrs, timeout):
                self.configs.saved_data["cluster_member"] = True
                Output.log("Completed setup and wait for master.")
                return True
        except RuntimeError:
            Output.log("setup_master: exception: {}".format(traceback.format_exc()))

        Output.log("Failed to setup master, did add_master succeed?")
        return False

    def is_tserver_up(self):

        master_addr = self.configs.saved_data.get("current_masters")
        if not master_addr:
            join_ip = self.configs.saved_data.get("join")
            master_ip = join_ip if join_ip else self.advertise_ip()
            master_addr = "{}:{}".format(master_ip,
                                     self.configs.saved_data.get("master_rpc_port"))

        if (not self.processes.get("master").is_running()
                or not self.processes.get("tserver").is_running()):
            Output.log("Failed waiting for yb-master/tserver... process died.", logging.ERROR)
            raise RuntimeError("process not running")

        cur_tservers = YBAdminProxy.get_tservers(master_addr)
        tserver_uuid = self.configs.saved_data.get("tserver_uuid")
        if not cur_tservers or tserver_uuid not in cur_tservers:
            raise RetryableError()

        Output.log("Found tserver uuid {} in list of tserver uuids {}.".format(
            tserver_uuid, cur_tservers))
        return True

    def wait_tserver(self, timeout=180):
        Output.log("Waiting for tserver ...")
        try:
            if retry_op(self.is_tserver_up, timeout):
                Output.log("Completed waiting for tserver.")
                return True
        except RuntimeError:
            Output.log("wait_tserver: exception: {}".format(traceback.format_exc()))

        Output.log("Failed to wait for tserver.")
        return False

    # In a multi-node cluster, the tserver initially knows just about its own master and the
    # master it is joining. After the cluster is formed, this method will attempt to
    # refresh the full list of masters so that the tserver can become aware of other masters.
    def update_tserver_master_addrs(self):
        tserver_cmd = self.processes["tserver"].cmd
        master_flag = [ flag for flag in tserver_cmd if flag.find(TS_MASTER_ADDRS_FLAG) >= 0 ]
        full_master_list = self.configs.saved_data.get("current_masters").split(",")

        if not full_master_list:
            Output.log("Unable to get all masters list, keeping tserver flag: {}".format(
                master_flag))
            return

        if len(full_master_list) < 3:
            my_master_ip = "{}:{}".format(
                self.advertise_ip(), self.configs.saved_data.get("master_rpc_port"))
            full_master_list = list(set(full_master_list + [ my_master_ip ]))
            Output.log("Got full master addrs list: {}".format(full_master_list))

        new_master_flag = "--{}={}".format(TS_MASTER_ADDRS_FLAG, ",".join(full_master_list))
        Output.log("Old master flag is: {} and new master flag is: {}".format(
            master_flag, new_master_flag))
        if master_flag:
            tserver_cmd.remove(master_flag[0])
        tserver_cmd += [new_master_flag]
        self.configs.saved_data["current_masters"] = ",".join(full_master_list)

    def wait_yw_login(self, yw_proxy, timeout=180, insecure=False):
        Output.log("Attempting to log in...")
        start_time = time.time()
        # Only the last error message is recorded if timed out.
        err = ""
        while time.time() - start_time < timeout:
            err = yw_proxy.insecure_login() if insecure else yw_proxy.login()
            if not err:
                Output.log("Login succeeded.")
                return ""
            time.sleep(.5)
        Output.log("Failed to login: {}".format(err))
        return "Timeout: " + err

    # Returns pretty output table.
    def get_status_string(self):

        join_ip = self.configs.saved_data.get("join")
        advertise_ip = self.advertise_ip()
        was_already_setup = self.configs.saved_data.get("cluster_member", False)

        # It is possible that masters have changed, try to find the latest
        # masters before computing the status string.
        master_web_addrs_ip = join_ip
        master_addrs = self.get_current_masters_from_api(join_ip)
        if not master_addrs:
            master_web_addrs_ip = advertise_ip
            master_addrs = self.get_current_masters_from_api(advertise_ip)
        self.configs.saved_data["current_masters"] = master_addrs
        Output.log("Master address list updated, new list: {}".format(master_addrs))

        master_web_addrs = "{}:{}".format(master_web_addrs_ip,
                                      self.configs.saved_data.get("master_webserver_port"))

        ycql_port = self.configs.saved_data.get("ycql_port")
        cql_hostname_param = ""
        cql_port_param = ""
        if advertise_ip != IP_LOCALHOST or ycql_port != DEFAULT_YCQL_PORT:
            cql_hostname_param =  advertise_ip
            cql_port_param = str(ycql_port)
        ycql_username, ycql_password, ycql_keyspace = self.setup_env_init.get_ycql_credentials()

        ysql_hostname_param = "-h {}".format(advertise_ip) if advertise_ip != IP_LOCALHOST else ""
        ysql_port = self.configs.saved_data.get("ysql_port")
        ysql_port_param = "-p {}".format(ysql_port) if ysql_port != DEFAULT_YSQL_PORT else ""
        ysql_username, ysql_password, ysql_db = self.setup_env_init.get_ysql_credentials()

        status_info = []
        # Make sure ascii escape characters for color encoding do not count towards char limit.
        if self.get_failed_node_processes():
            title = Output.make_bold(Output.make_red(SCRIPT_NAME))
            extra_len = len(Output.make_bold(Output.make_red("")))
            status = "Stopped"
            status_info = [
                (Output.make_yellow("Status"), status),
            ]
        else:
            title = Output.make_bold(Output.make_green(SCRIPT_NAME))
            extra_len = len(Output.make_bold(Output.make_green("")))
            # Check if there is a leader yet.
            # We can use a smaller timeout here instead of the regular 60 secs.
            # In case of starting up via yugabyted, we have already given enough time to
            # the leader election
            # In case of manual start or some other route, we can have a smaller timeout
            status = ""
            if was_already_setup:
                if master_addrs:
                    status = "Running."
            else:
                if self.wait_get_all_masters(timeout=10):
                    status = "Running."
                else:
                    status = "Status command timed out as YugabyteDB \"yb-master\" " + \
                                "process is not responding."

            enabled_security_features = []
            if self.configs.temp_data.get("yugabyted_cmd") == "status":
                encryption_enabled = self.is_encryption_at_rest_enabled()
                if encryption_enabled is None:
                    Output.log("Error checking status of " +
                        "encryption-at-rest.")
                elif encryption_enabled:
                        enabled_security_features.append("Encryption-at-rest")

            is_secure = self.configs.saved_data.get("secure")
            if is_secure:
                if self.is_leader_master_secure(master_web_addrs):
                    enabled_security_features.append("Encryption-in-transit")
                if self.configs.saved_data.get("ysql_enable_auth") and \
                    self.configs.saved_data.get("use_cassandra_authentication"):
                    enabled_security_features.append("Password Authentication")

            rf = self.configs.temp_data.get("replication_factor")
            if not rf and self.configs.temp_data.get("yugabyted_cmd") == "start":
                Output.init_animation("Verifying data placement constraint " +
                            "on the YugabyteDB Cluster...")
                rf = YBAdminProxy.get_cluster_rf(master_addrs)
                Output.update_animation("Data placement constraint successfully verified")
            else:
                rf = YBAdminProxy.get_cluster_rf(master_addrs)
            status_info = [
                (Output.make_yellow("Status"), status),
                (Output.make_yellow("Replication Factor"), rf),
            ]

            if enabled_security_features:
                status_info += [
                    (Output.make_yellow("Security Features"), ", ".join(enabled_security_features))
                ]


        ysql_flags = " {} {} -U {} -d {}".format(ysql_hostname_param, ysql_port_param,
                        ysql_username, ysql_db)
        ycql_flags = " {} {} -u {}".format(cql_hostname_param, cql_port_param,
                        ycql_username)
        if ycql_keyspace is not None:
            ycql_flags = ycql_flags + " -k {}".format(ycql_keyspace)
        if self.configs.saved_data.get("secure"):
            ycql_flags = ycql_flags + " --ssl"

        # TODO: Check if YW is disabled. This could be from saving --ui flag, checking PID,
        # or some other method. The first is not preferred because it would deviate from how the
        # other saved data works in that they persist between runs but --ui shoudln't.

        yw_status = "http://{}:{}".format(advertise_ip,
                                          self.configs.saved_data.get("webserver_port"))
        yugabyted_ui_status = "http://{}:{}".format(advertise_ip,
                                          self.configs.saved_data.get("yugabyted_ui_port"))
        yb_master_status = "http://{}:{}".format(advertise_ip,
                                          self.configs.saved_data.get("master_webserver_port"))
        console_desc = "Web console"
        if self.configs.saved_data.get("ui"):
            try:
                response = urlopen(Request(yugabyted_ui_status))
                if response.code == 200:
                    console_desc = "YugabyteDB UI"
                    status_info += [ (Output.make_yellow(console_desc), yugabyted_ui_status), ]
                else:
                    status_info += [ (Output.make_yellow(console_desc), yb_master_status), ]
            except HTTPError as http_err:
                Output.log('HTTP error occurred while fetching YugabyteDB UI {}', http_err)
                status_info += [ (Output.make_yellow(console_desc), yb_master_status), ]
            except Exception as err:
                Output.log('HTTP error occurred while fetching YugabyteDB UI {}', err)
                status_info += [ (Output.make_yellow(console_desc), yb_master_status), ]
        else:
            status_info += [ (Output.make_yellow(console_desc), yb_master_status), ]

        status_info += [
            (Output.make_yellow("JDBC"), "jdbc:postgresql://{}:{}/{}?user={}&password={}".
                format(advertise_ip, ysql_port, ysql_db, ysql_username, ysql_password)),
            (Output.make_yellow("YSQL"), "bin/ysqlsh{}".format(ysql_flags)),
            (Output.make_yellow("YCQL"), "bin/ycqlsh{}".format(ycql_flags)),
            (Output.make_yellow("Data Dir"), self.configs.saved_data.get("data_dir")),
            (Output.make_yellow("Log Dir"), self.configs.saved_data.get("log_dir")),
            (Output.make_yellow("Universe UUID"), self.configs.saved_data.get("universe_uuid"))
        ]
        div_line = "+" + "-" * 106 + "+" + "\n"
        status = "\n" + div_line
        status += ("| {:^" + str(104
         + extra_len) + "} |\n").format(title)
        status += div_line
        for k, v in status_info:
            extra_len = len(Output.make_yellow(""))
            status += ("| {:" + str(20 + extra_len) + "}: {:<82} |\n").format(k,
                                                                              v if v is not None
                                                                              else "None")
        status += div_line
        return status

    # Returns pretty output table
    def get_status_string_common(self, status_info, status_display_info = None):
        title = Output.make_bold(Output.make_green(SCRIPT_NAME))
        extra_len = len(Output.make_bold(Output.make_green("")))

        max_len = 0
        for k, v in status_info:
            max_len = max(max_len, len(v))

        div_line = "+" + "-" * (max_len + 33) + "+" + "\n"
        status = "\n" + div_line
        status += ("| {:^" + str(max_len + 31 + extra_len) + "} |\n").format(title)
        status += div_line
        for k, v in status_info:
            func = None
            if status_display_info is not None and v in status_display_info.keys():
                func = status_display_info.get(v)
            extra_len = len(Output.make_yellow(""))
            status += ("| {:" + str(27 + extra_len) + "}: ").format(k)
            if func is not None:
                status += ("{:<" + str(max_len + 2 + len(func(""))) + "} |\n").format(func(v))
            else:
                status += ("{:<" + str(max_len + 2) + "} |\n").format(v)
        status += div_line
        return status

    # Callhome loop. Sends data every minute for the first hour, then every hour after.
    def callhome_loop(self):
        num_times_called = 0
        initial_interval = 60
        final_interval = 3600
        while not self.stop_callhome:
            self.callhome()
            num_times_called += 1
            # Send callhome data more often in initial hour.
            time.sleep(initial_interval if num_times_called < 60 else final_interval)

    # Collects callhome data and sends it.
    def callhome(self):
        if self.configs.saved_data.get("callhome"):
            try:
                url = "http://diagnostics.yugabyte.com"
                headers = {
                    "Content-Type": "application/json",
                    "User-Agent": "Mozilla",
                }
                data = Diagnostics(self.configs).get_data(self.processes)
                req = Request(url, headers=headers, data=data.encode('utf8'))
                resp = urlopen(req)
            except Exception as e:
                Output.log("Callhome failed: " + str(e))
                pass

    # update the master address list every min for the first half hour, then every hour after.
    def update_masters_list_loop(self):
        num_times_cmd_executed = 0
        initial_interval = 60
        final_interval = 3600
        try:
            while True:
                self.update_master_list_on_background_thread()
                num_times_cmd_executed += 1
                time.sleep(initial_interval
                        if num_times_cmd_executed < 30 else final_interval)
        except Exception as e:
                Output.log("update_masters_list: " + str(e))
                pass

    def update_master_list_on_background_thread(self):

        # global _global_current_list_of_masters
        current_master_list = self.configs.saved_data.get("current_masters").split(",")
        Output.log("thread-uml: current masters {}".format(current_master_list))

        # thread for updating the master address list in the background
        # First attempt for /masters using the --join flag
        masters_csv = self.get_current_masters_from_api(self.configs.saved_data.get("join"))
        if not masters_csv:
            # second attempt for /masters using the --advertise_address flag
            masters_csv = self.get_current_masters_from_api(self.advertise_ip())
            if not masters_csv:
                Output.log("thread-uml: Unable to query for all masters list, " +
                    "keeping masters list: {}".format(current_master_list))
                return

        full_master_list = masters_csv.split(",")
        # check if masters have changed since last refresh, if not return
        if_any_new_masters = set(full_master_list).difference(current_master_list)
        if if_any_new_masters:
            self.configs.saved_data["current_masters"] = masters_csv
            Output.log("thread-uml: master list updated, old list: {} ".format(
                current_master_list) + "new list: {}".format(full_master_list))

            # Persist the config if masters have changed
            self.configs.save_configs()


    # Calls func after receiving certain exit signals.
    def set_signals(self, func):
        for sig in EXIT_SIGNALS:
            signal(sig, func)

    # Returns true if Java is installed. While Java 8+ is necessary for YW, we don't explicitly
    # check for it so that future version format changes (e.g. Java 1.4 to Java 5) won't give
    # wrong error messages.
    def java_installed(self):
        try:
            cmd = ["java", "-version"]
            java_info = subprocess.check_output(cmd, stderr=subprocess.STDOUT)
            return java_info is not None
        except (OSError, subprocess.CalledProcessError) as e:
            Output.log("Failed to find java: {}".format(e), logging.ERROR)
            return False

    # Check whether the hostnames or IP provided is in correct format.
    def validate_hostname_ip(self, ip):
        # Regex expression for validating IPv4
        ipv4_regex = "^((25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\.){3}(25[0-5]|2[0-4]"\
            "[0-9]|1[0-9][0-9]|[1-9]?[0-9])$"

        # Regex expression for validating IPv6
        ipv6_regex = "((([0-9a-fA-F]){1,4})\\:){7}([0-9a-fA-F]){1,4}"

        # Regex expression for validating DNS names
        dns_regex = "^((?!-)[A-Za-z0-9-]" + "{1,63}(?<!-)\\.)" +"+[A-Za-z]{2,6}"

        ipv4_pattern = re.compile(ipv4_regex)
        ipv6_pattern = re.compile(ipv6_regex)
        dns_pattern = re.compile(dns_regex)

        # Checking if it is not a valid IPv4 or IPv6 addresses
        if not (re.search(ipv4_pattern, ip) or
                re.search(ipv6_pattern, ip) or
                re.search(dns_pattern, ip)):
            return False

        if re.search(dns_pattern, ip):
            self.configs.saved_data["dns_enabled"] = True

        return True

    # Returns a list of invalid IPs from the list of IPs provided.
    def get_invalid_ips(self, ips):
        invalid_ips = []
        for ip in ips:
            if not self.validate_hostname_ip(ip):
                invalid_ips.append(ip)

        return invalid_ips

    def find_ip_address_of_node(self):

        host_name = self.find_hostname_of_node()
        host_ip = socket.gethostbyname(host_name)

        return host_ip

    def find_hostname_of_node(self):
        fqdn = socket.getfqdn()

        if "localhost" in fqdn:
            fqdn = socket.getaddrinfo(socket.gethostname(), None, socket.AF_INET,
                                  socket.SOCK_DGRAM, socket.IPPROTO_IP,
                                  socket.AI_CANONNAME)[0][3]
            if "localhost" in fqdn:
                fqdn = socket.gethostname()

        return fqdn

    # Check whether the leader master is secure.
    def is_leader_master_secure(self, master_hostport):
        try:
            leaderMasterURL = "http://{}/api/v1/varz".format(master_hostport)
            response = urlopen(Request(leaderMasterURL))
            jsonResponseFromMaster = json.load(response)
            listOfAllFlags = jsonResponseFromMaster.get("flags")

            encryptionFlag = [flag for flag in listOfAllFlags if
                flag.get("name") == "use_node_to_node_encryption"]

            return encryptionFlag[0].get("value") == "true"

        except HTTPError as http_err:
            print('HTTP error occurred while checking for security of leader master: {}', http_err)
        except Exception as err:
            print('Other error occurred while checking for security of leader master: {}', err)

    # Parse the config file and input parent flags to validate and set them.
    # Parent flags: --config, --data_dir, --log_dir
    def validate_and_set_parent_configs(self, args):

        home_dir = os.path.expanduser("~")
        default_base_dir = os.path.join(home_dir, "var")
        default_conf_path = os.path.join(default_base_dir, "conf", "{}.conf".format(SCRIPT_NAME))
        base_dir = os.path.abspath(os.path.expanduser(args.base_dir)) if args.base_dir \
            else default_base_dir
        base_dir_conf = ''
        if args.base_dir:
            base_dir_conf = os.path.join(base_dir, "conf", "{}.conf".format(SCRIPT_NAME))

        has_errors = False

        self.conf_file = args.config or base_dir_conf or \
                         Configs.get_brew_config() or default_conf_path
        self.conf_file = os.path.realpath(os.path.expanduser(self.conf_file))

        conf_dir = os.path.dirname(self.conf_file)
        if not os.path.isdir(conf_dir):
            os.makedirs(conf_dir)

        self.configs = Configs.parse_config_file(self.conf_file, base_dir)

        for path_args in ("data_dir", "log_dir"):
            path = getattr(args, path_args, None)
            if path:
                setattr(args, path_args, os.path.abspath(os.path.realpath(path)))

        if args.data_dir is not None:
            args.data_dir = os.path.expanduser(args.data_dir)

            config_data_dir = self.configs.saved_data.get("data_dir")
            if (config_data_dir and os.path.exists(config_data_dir) and
                    config_data_dir != args.data_dir):
                has_errors = True
                # TODO: Gradefully handle this case... User should be able to override config.
                Output.print_out(
                    "Data directory already exists at {}.".format(config_data_dir))

        if args.log_dir is not None:
            args.log_dir = os.path.expanduser(args.log_dir)

            config_log_dir = self.configs.saved_data.get("log_dir")
            if (config_log_dir and os.path.exists(config_log_dir) and
                    config_log_dir != args.log_dir):
                Output.print_out(
                    "Old log directory already exists at {}. New logs will go to {}".format(
                        config_log_dir, args.log_dir))

        if has_errors:
            sys.exit(1)

        parent_flags = ["config", "log_dir", "data_dir"]
        # Override configs and defaults with user specified variables
        for k, v in get_kv(args.__dict__):
            if (v is not None and k in parent_flags and k in self.configs.saved_data
                    and v != self.configs.saved_data.get(k)):
                self.configs.saved_data[k] = v

        data_dir = self.configs.saved_data["data_dir"]
        log_dir = self.configs.saved_data["log_dir"]
        self.configs.save_configs()

        if not os.path.isdir(data_dir):
            os.makedirs(data_dir)
        if not os.path.isdir(log_dir):
            os.makedirs(log_dir)

        self.script = ScriptProcessManager(log_dir, data_dir)

    # Check and validate the flags regarding the secure deployment of the node.
    # Check whether the certs files are present or not.
    # Create certs if it is 1-node cluster throw error otherwise.
    def validate_security_configs(self, args):
        home_dir = os.path.expanduser("~")
        default_base_dir = os.path.join(home_dir, "var")
        base_dir = os.path.abspath(args.base_dir) if args.base_dir else default_base_dir

        default_certs_dir = os.path.join(base_dir, "certs")

        certs_dir = self.configs.saved_data.get("certs_dir") or \
                    default_certs_dir

        has_errors = False

        certs_files = ["ca.crt", "node."+args.advertise_address+".crt",
                    "node."+args.advertise_address+".key"]

        if args.certs_dir is not None:
            args.certs_dir = os.path.expanduser(args.certs_path)

            if not os.path.exists(args.certs_dir):
                # Case Scenario: When the directory provided by the user through
                # --certs_dir flag in CLI does not exists.
                has_errors = True
                Output.print_out(Output.make_red("ERROR") +
                    ": Trying to use {} as the certs directory. ".format(args.certs_dir) +
                    "No such directory found. Please provide the correct directory " +
                    "where the certificates are through --certs_dir flag.")
            else:
                if not check_files_in_path(args.certs_dir, certs_files):
                    # Case Scenario: When the directory provided by the user through --certs_dir
                    # flag in CLI exists but doesn't have the correct certs.
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") +
                        ": Trying to use {} as the certs ".format(args.certs_dir) +
                        "directory. Correct certs not found in this directory. Please " +
                        "either use 'cert generate_server_certs' command to create " +
                        "certificates or follow this doc to create your own " +
                        "certificates: {}".format(GENERATE_SERVER_CERTS))
                else:
                    # Case Scenario: When the directory provided by the user through
                    # --certs_dir flag in CLI exists and have the correct certs.
                    Output.log("Found certs at {}.".format(args.certs_dir))
        else:
            if os.path.exists(certs_dir):
                if not check_files_in_path(certs_dir, certs_files):
                    # Case Scenario: When the default certs directory or the certs directory saved
                    # in conf file exists but doesn't have the correct certs.
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") +
                        ": Trying to use {} as the certs ".format(certs_dir) +
                        "directory. Correct certs not found in this directory. Please " +
                        "either use 'cert generate_server_certs' command to create " +
                        "certificates or follow this doc to create your own " +
                        "certificates: {}".format(GENERATE_SERVER_CERTS))
                else:
                    # Case Scenario: When the default certs directory or the certs directory saved
                    # in conf file exists and has the correct certs.
                    Output.log("Found certs at {}.".format(certs_dir))
            else:
                if certs_dir != default_certs_dir:
                    # Case Scenario: When the certs directory is mentioned in the configs
                    # file but the directory doesn't exist.
                    # Example: When the user starts a secure cluster, then stops it.
                    # Then due to some reason the certs directory that was being used has
                    # been deleted. Now when the user tries to restart the node,
                    # yugabyted will try to use the same dir as it was stored in the config file,
                    # but the directory doesn't exist.
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") +
                        ": The directory mentioned in the --cert_dir value of the configs file " +
                        "doen't exist. Please create the directory and copy the certs into that " +
                        "directory.")
                elif args.join:
                    # Case Scenario: When the user is trying to start and join a node
                    # to a secure cluster but the generated certs are neither present
                    # in the default directory nor given through --certs_dir flag.
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") +
                        ": Trying to start a secure node but couldn't find the certs at " +
                        "default directory. Cannot create new certs as the --join flag " +
                        "was used. Please generate the node certificates in 1 node and " +
                        "copy them to other nodes.")
                else:
                    # Case Scenario: When the user is trying to start a secure node but
                    # the generated certs are neither present in default directory nor
                    # given through --certs_dir flag. Create new certs in this case.
                    Output.log("Couldn't find the certs so creating new certificates.")
                    if self.check_openssl():
                        has_errors = True
                        Output.print_out(Output.make_red("Error") + ": openssl " +
                            "not installed. Can't create certificates.")

                    if not has_errors:
                        gen_certs_dir = self.configs.saved_data.get("gen_certs_dir")
                        root_certs_dir = os.path.join(gen_certs_dir, "root-ca")

                        if not self.generate_ca_certs(root_certs_dir=root_certs_dir):
                            has_errors = True
                            Output.print_out(Output.make_red("Error") +
                                "Cert generation failed. Please check the logs.")

                        hostnames = [args.advertise_address]
                        generated_certs_hostnames = self.generate_node_server_certs(
                                            hostnames=hostnames, gen_certs_dir=gen_certs_dir)
                        if not has_errors and not len(generated_certs_hostnames):
                            has_errors = True
                            Output.print_out(Output.make_red("Error") +
                                "Cert generation failed. Please check the logs.")

                        if not has_errors:
                            os.makedirs(certs_dir)

                            for file in certs_files:
                                shutil.copy2(os.path.join(gen_certs_dir, args.advertise_address,
                                                            file), certs_dir)

            args.certs_dir = certs_dir



        if has_errors:
            sys.exit(1)

    # Find the correct security nature of the deployment of the node by checking
    # secure or insecure flags passed by the user and secure and insecure options
    # present in the config file
    def find_security_nature_of_deployment(self, args):
        if args.secure and not args.insecure:
            # If --secure flag is passed in the CLI and --insecure is not. Node should be
            # deployed in secure mode.
            args.secure = True
            args.insecure = False
            return

        if args.insecure and not args.secure:
            # If --insecure flag is passed in the CLI and --secure is not. Node should be
            # deployed in insecure mode.
            args.secure = False
            args.insecure = True
            return

        if args.secure and args.insecure:
            # If both --secure and --insecure flags are passed in the CLI, show an error.
            Output.log_error_and_exit(Output.make_red("ERROR") +
                ": --secure flag can't be used together with --insecure flag")

        if not self.configs.saved_data.get("secure"):
            # If neither --secure nor --insecure flag is passed in the CLI and the value
            # of --secure in conf file is False then start the node in insecure mode
            args.secure = False
            args.insecure = True
            return

        if not self.configs.saved_data.get("insecure"):
            # If neither --secure nor --insecure flag is passed in the CLI and value of
            # --insecure in conf file is False and --secure is True then start
            # the node in secure mode
            args.secure = True
            args.insecure = False
            return

        # If neither --secure nor --insecure flag and both --secure and --insecure have
        # values in conf file have value as True, show an error.
        Output.log_error_and_exit(Output.make_red("ERROR") +
            ": config file {} has both secure and ".format(self.conf_file) +
            "insecure set to True. Please change one of them to False")

    # Parse config file and input args. Validate them and save any new configs.
    def validate_and_set_configs(self, args):

        has_errors = False

        if args.parser == "collect_logs":
            self.configs.temp_data["collect_logs_stdout"] = args.stdout

        if args.parser == "admin_operation":
            if not args.command:
                has_errors = True
                Output.print_and_log(Output.make_red("Error:") + " --command flag is empty. " +
                                 "Please specify a yb-admin command to execute.")
                # Output.print_out("--command flag is empty. " +
                #                  "Specify a yb-admin command to execute.")
            else:
                self.configs.temp_data["admin_command"] = args.command

            if args.master_addresses is not None:
                self.configs.temp_data[
                    "admin_operation_master_addresses"] = args.master_addresses

        if args.parser == "data_placement":
            if args.fault_tolerance is not None:
                if args.fault_tolerance.lower() in FAULT_TOLERANCE_CHOICES:
                    self.configs.temp_data["fault_tolerance"] = args.fault_tolerance.lower()
                else:
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") + ": " +
                        "Incorrect fault_tolerance value specified. " +
                        "Please specify one of the following - zone, region or cloud ")

            if args.constraint_value is not None:
                data_constraints = args.constraint_value.split(",")
                has_errors = False
                for constraint in data_constraints:
                    cloud_info = constraint.split(".")
                    if (len(cloud_info) == 3):
                        for value in cloud_info:
                            if not value:
                                has_errors=True
                    else:
                        has_errors = True

                if has_errors:
                    Output.print_out(
                        "Incorrect value specified for constraint_value. " +
                        "Please specify comma sperated value with format " +
                        "- cloudprovider.region.zone".format(
                            args.constraint_value))
                else:
                    self.configs.temp_data[
                        "constraint_value"] = args.constraint_value

            if args.rf is not None:
                self.configs.temp_data["replication_factor"] = str(args.rf)
            else:
                self.configs.temp_data["replication_factor"] = str("3")

        if args.parser == "generate_server_certs":
            if args.hostnames is None:
                has_errors = True
                Output.print_and_log(Output.make_red("Error") + ": Please provide the " +
                    "--hostnames along with \'yugabyted cert generate_server_certs\' command.")
            else:
                hostnames = args.hostnames.split(",")
                invalid_hostnames = self.get_invalid_ips(hostnames)
                if invalid_hostnames:
                    if len(invalid_hostnames) > 1:
                        msg = Output.make_red("ERROR") + ": Hostnames {} are not valid IPv4 or "\
                            "IPv6 addresses. Please try again with valid "\
                            "hostnames.".format(",".join(invalid_hostnames))
                    else:
                        msg = Output.make_red("ERROR") + ": Hostname {} is not a valid IPv4 or "\
                            "IPv6 address. Please try again with valid "\
                            "hostnames.".format(",".join(invalid_hostnames))

                    has_errors = True
                    Output.print_and_log(msg)

            self.configs.temp_data["hostnames"] = args.hostnames

        if args.parser == "encrypt_at_rest":
            if not args.enable and not args.disable:
                has_errors = True
                Output.print_out(Output.make_red("ERROR") +
                    ": Either --enable or --disable flag has to be provided.")

            if args.enable and args.disable:
                has_errors = True
                Output.print_out(Output.make_red("ERROR") +
                    ": --enable and --disable flags cannot be used together.")
            elif args.enable:
                self.configs.temp_data["enable_encrypt_at_rest"] = args.enable
            elif args.disable:
                self.configs.temp_data["disable_encrypt_at_rest"] = args.disable

        if args.parser == "start":
            if args.cloud_location is not None:
                cloud_location = args.cloud_location.split(".")
                if len(cloud_location) == 3:
                    self.configs.saved_data["cloud_provider"] = cloud_location[0]
                    self.configs.saved_data["cloud_region"] = cloud_location[1]
                    self.configs.saved_data["cloud_zone"] = cloud_location[2]
                else:
                    Output.print_out(Output.make_red("ERROR") +
                        ": Incorrect format used for flag --cloud_location. " +
                        "Please use cloud.region.zone format.")
                    has_errors = True

            if args.fault_tolerance is not None:
                if args.fault_tolerance.lower() in START_FAULT_TOLERANCE_CHOICES:
                    self.configs.saved_data["fault_tolerance"] = args.fault_tolerance.lower()
                else:
                    has_errors = True
                    Output.print_out(Output.make_red("ERROR") + ": " +
                        "Incorrect fault_tolerance value specified. " +
                        "Please specify one of the following - zone, region or cloud ")

            if args.listen is not None:
                if args.advertise_address is not None and args.listen != args.advertise_address:
                    Output.print_out(Output.make_red("ERROR") +
                        ": --listen and --advertise_address flags " +
                        "are same. --listen is depricated. Can't have different values for them.")
                    has_errors = True
                args.advertise_address = args.listen

            if args.advertise_address is None:
                if not self.configs.saved_data.get("advertise_address"):
                    if OS_NAME == "Linux":
                        # Case Scenario: When advertise_address has no value in conf file
                        # and the OS is Linux, set the advertise address to the private IP
                        # of the machine.
                        args.advertise_address = self.find_ip_address_of_node()
                    else:
                        # Case Scenario: When advertise_address has no value in conf file
                        # and the OS is Mac, set the advertise address to 127.0.0.1.
                        args.advertise_address = IP_LOCALHOST
                else:
                    # Case Scenario: When advertise_address has a value in conf file and then
                    # use that regardless of the OS.
                    args.advertise_address = self.configs.saved_data.get("advertise_address")
            else:
                if not self.validate_hostname_ip(args.advertise_address):
                    has_errors = True
                    Output.print_and_log(Output.make_red("ERROR") + ": --advertise_address " +
                        "provided is not a valid IPv4 or IPv6 address. " +
                        "Please try again with a valid IP.")

            if args.daemon is not None:
                if args.background is not None and \
                        self.parse_bool(args.daemon) != self.parse_bool(args.background):
                    Output.print_out(Output.make_red("ERROR") +
                        ": --daemon and --background flags " +
                        "are same. --daemon is depricated. Can't have different values for them.")
                    has_errors = True
                args.background = args.daemon

            if args.background is None:
                args.background = "True"

            if args.join is not None:
                try:
                    leaderMasterURL = "http://{}:7000/api/v1/varz".format(args.join)
                    response = urlopen(Request(leaderMasterURL))
                except HTTPError as http_err:
                    Output.log("HTTP Error occured while hitting the api endpoint " +
                        "http://{}:7000/api/v1/varz: {}".format(args.join, http_err))
                    Output.log_error_and_exit(Output.make_red("ERROR:") + "master at the join ip " +
                        "provided is not reachable.")
                except Exception as err:
                    Output.log("Error occured while hitting the api endpoint " +
                        "http://{}:7000/api/v1/varz: {}".format(args.join, err))
                    Output.log_error_and_exit(Output.make_red("ERROR:") + "master at the join ip " +
                        "provided is not reachable.")


            self.find_security_nature_of_deployment(args)

            if (args.certs_dir is not None) and (not args.secure):
                # Case Sceneario: When certs_dir flag is passed without secure flag.
                has_errors = True
                Output.print_out(Output.make_red("ERROR") +
                    ": --certs_dir flag needs to be accompanied with the --secure flag.")

            if args.insecure:
                if args.join:
                    master_hostport = "{}:7000".format(args.join)
                    if self.is_leader_master_secure(master_hostport):
                        # Case Scenario: When a User starts the 1st node in secure mode and tries
                        # to start the second node in insecure mode
                        has_errors = True
                        Output.print_out(Output.make_red("ERROR") + ": The node whose " +
                            "IP was provided in --join flag has SSL/TLS enabled. Cannot join a " +
                            "secure and an insecure node.")
            elif args.secure:
                if args.join:
                    master_hostport = "{}:7000".format(args.join)
                    if not self.is_leader_master_secure(master_hostport):
                        # Case Scenario: When the user starts the 1st node in insecure mode and
                        # tries to start the second node in secure mode.
                        has_errors = True
                        Output.print_out(Output.make_red("ERROR") + ": The node whose " +
                            "IP was provided --join flag does not have SSL/TLS enabled. Cannot " +
                            "join a secure and an insecure node.")

                if not has_errors:
                    self.validate_security_configs(args)

                    args.ysql_enable_auth="true"
                    args.use_cassandra_authentication="true"

                    self.configs.saved_data["ca_cert_file_path"] = os.path.join(args.certs_dir,
                                                                                    "ca.crt")

            args.background = self.parse_bool(args.background)
            if args.ui is not None:
                args.ui = self.parse_bool(args.ui)
            else:
                args.ui = self.configs.saved_data.get("ui")

            if args.callhome is not None:
                args.callhome = self.parse_bool(args.callhome)
            elif os.environ.get("YB_DISABLE_CALLHOME") is not None:
                args.callhome = os.environ.get("YB_DISABLE_CALLHOME") not in TRUE_CHOICES
            else:
                args.callhome = DEFAULT_CALLHOME

            # Set authentication flags same as provided in the command-line flags.
            if args.ysql_enable_auth:
                args.ysql_enable_auth = self.parse_bool(args.ysql_enable_auth)

            if args.use_cassandra_authentication:
                args.use_cassandra_authentication = self.parse_bool(args.use_cassandra_authentication)

            # Set authentication flags to True, if it is first-run and
            # have required environment variables to enforce the authentication.
            if not self.is_yb_initialized():
                if self.setup_env_init.is_exists('YSQL_PASSWORD'):
                    args.ysql_enable_auth = True

                # Add use_cassandra_authentication flag to enforce authentication for YCQL
                if self.setup_env_init.is_exists('YCQL_USER') or \
                        self.setup_env_init.is_exists('YCQL_PASSWORD'):
                    args.use_cassandra_authentication = True

            self.configs.temp_data["background"] = args.background
            self.configs.saved_data["ui"] = args.ui
            self.configs.temp_data["initial_scripts_dir"] = args.initial_scripts_dir

        if self.configs.saved_data.get("database_password") is not None:
            self.setup_env_init.update_passwords(self.configs.saved_data.get("database_password"))

        if has_errors:
            sys.exit(1)

        parent_flags = ["config", "log_dir", "data_dir"]
        # Override configs and defaults with user specified variables
        for k, v in get_kv(args.__dict__):
            if (v is not None and k not in parent_flags and k in self.configs.saved_data
                    and v != self.configs.saved_data.get(k)):
                self.configs.saved_data[k] = v


    def parse_bool(self, config):
        return config in TRUE_CHOICES

    def run(self):
        # Parent subparser for common args
        common_parser = argparse.ArgumentParser(add_help=False)
        common_parser.add_argument(
            "--config", help="{} configuration file path".format(
                              SCRIPT_NAME), metavar="")
        # TODO: Refactor data_dir to be a list for multi-node. How should the config file and
        # data dir be set for local mulit-node setups? Note: daemon mode may be affected.
        common_parser.add_argument(
            "--data_dir", help="Directory where {} will store data.".format(SCRIPT_NAME),
                metavar="")
        common_parser.add_argument(
            "--base_dir", help="Directory under which {} will store data, conf and logs".format(
                SCRIPT_NAME), metavar="")
        common_parser.add_argument(
            "--log_dir", help="Directory to store {} logs.".format(SCRIPT_NAME), metavar="")

        start_msg = "To start YugabyteDB cluster, run '{}'.\n\n".format(
            Output.make_green("{} start".format(SCRIPT_NAME)))
        start_msg += "Find more information at: {}".format(Output.make_underline(YUGABYTED_LINK))
        parser = PrettyArgParser(description=start_msg)
        all_parsers = {"default": parser}
        subparsers = parser.add_subparsers(dest="parser", metavar="")
        subparsers.required = True
        for cmd, description in (
                ("start", "Start YugabyteDB cluster."),
                ("stop", "Stop running YugabyteDB cluster."),
                ("destroy", "Destroy YugabyteDB cluster and remove data."),
                ("status", "Print status of YugabyteDB cluster."),
                ("version", "Release version of YugabyteDB cluster."),
                ("collect_logs", "Collect and package logs for troubleshooting.")):
            example = ""
            if EXAMPLE[cmd]:
                example = Output.make_yellow("Examples") + ": \n" + EXAMPLE[cmd]
            subparser = subparsers.add_parser(cmd, description=example,
                                                help=description, parents=[common_parser])
            subparser.epilog = EPILOG_SPECIFIC[cmd] + EPILOG_COMMON
            func = getattr(self, cmd, None)
            subparser.set_defaults(func=func)
            all_parsers[cmd] = subparser

        # Add ysql and ycql CLI options
        connect = subparsers.add_parser("connect",
                    help="Connect to YugabyteDB cluster through the CLI.")
        all_parsers["connect"] = connect
        connect_subparser = connect.add_subparsers(dest="parser", metavar="")
        connect_subparser.required = True
        for api in YUGABYTE_API_CLIENT_PROGRAMS:
            cur_parser = connect_subparser.add_parser(
                api, help="Use {} through the CLI.".format(api.upper()), parents=[common_parser])
            func = getattr(self, "connect_{}".format(api), None)
            cur_parser.set_defaults(func=func)
            all_parsers[api] = cur_parser

        # Add demo commands to create, connect, and destroy.

        demo_parser = subparsers.add_parser("demo", help="Load and interact with preset demo data.")
        all_parsers["demo"] = demo_parser
        demo_subparsers = demo_parser.add_subparsers(dest="parser", metavar="")
        demo_subparsers.required = True
        for cmd, description in (
                ("connect", "Connect to the demo database."),
                ("destroy", "Destroy the demo database.")):
            subparser = demo_subparsers.add_parser(cmd, help=description, parents=[common_parser])
            parser_name = cmd + "_demo"
            func = getattr(self, parser_name, None)
            subparser.set_defaults(func=func)
            all_parsers[parser_name] = subparser

        # Add cert generation options
        example = Output.make_yellow("Examples") + ": \n" + EXAMPLE["cert"]
        cert_parser = subparsers.add_parser("cert", description=example,
                                                help="Generate SSL cerificates")
        all_parsers["cert"] = cert_parser
        cert_subparsers = cert_parser.add_subparsers(dest="parser", metavar="")
        cert_subparsers.required = True
        for cmd, description in (
                ("generate_server_certs", "Generate node server certificates."),):
            subparser = cert_subparsers.add_parser(cmd, help=description, parents=[common_parser])
            parser_name = "cert_" + cmd
            func = getattr(self, parser_name, None)
            subparser.set_defaults(func=func)
            all_parsers[parser_name] = subparser

        # Generate node server certs of given hostname
        for cmd in ("cert_generate_server_certs",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--hostnames", help="Hostnames of the nodes to be added in the cluster. " +
                "Mandatory flag.", metavar="")

        # Docker: Redirect the logs.tar.gz to stdout
        for cmd in ("collect_logs",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--stdout", help="Redirect the logs.tar.gz file's content to stdout. Ex: "+
                "docker exec <container-id> bin/yugabyted collect_logs --stdout > yugabyted.tar.gz",
                action="store_true", default=False)

        example = Output.make_yellow("Examples") + ": \n" + EXAMPLE["configure"]
        configure_parser = subparsers.add_parser("configure", description=example,
                                                help="Configure data placement or " +
                                                "toggle encryption at rest for " +
                                                "the cluster.", parents=[common_parser])
        all_parsers["configure"] = configure_parser
        configure_subparsers = configure_parser.add_subparsers(dest="parser", metavar="")
        configure_subparsers.required = True
        for cmd, description in (
                ("data_placement", "Configure multi-zone/multi-region cluster."),
                ("encrypt_at_rest", "Enable or disable encryption at rest."),
                ("admin_operation", "Run yb-admin command on the YugabyteDB cluster.")):
            example = ""
            if EXAMPLE[cmd]:
                example = Output.make_yellow("Examples") + ": \n" + EXAMPLE[cmd]
            subparser = configure_subparsers.add_parser(cmd, help=description, description=example,
                                parents=[common_parser])
            parser_name = "configure_" + cmd
            func = getattr(self, parser_name, None)
            subparser.set_defaults(func=func)
            all_parsers[parser_name] = subparser

        # Flags for muti-zone/multi-region configuration.
        for cmd in ("configure_data_placement",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--fault_tolerance", help="No more than 1 node in the same " +
                "fault tolerance can be a master",
                metavar="")
            cur_parser.add_argument(
                "--constraint_value", help="Data placement constriant to be applied " +
                "on the YugabyteDB Cluster",
                metavar="")
            cur_parser.add_argument(
                "--rf", help="Set the replication factor for each tablet",
                metavar="")

        # Flags for encryption at rest
        for cmd in ("configure_encrypt_at_rest",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--enable", help="Enable encryption at rest for the cluster. No need to set a " +
                "value for the flag. Use --enable or --disable flag to toggle encryption " +
                "features on a YugabyteDB cluster.",
                action="store_true")
            cur_parser.add_argument(
                "--disable", help="Disable encryption at rest for the cluster. No need to set a " +
                "value for the flag. Use --enable or --disable flag to toggle encryption " +
                "features on a YugabyteDB cluster.",
                action="store_true")

        # flags for admin operations
        for cmd in ("configure_admin_operation",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--command", help="specify the yb-admin command to be executed " +
                                        "on the YugabyteDB Cluster",
                metavar="")
            cur_parser.add_argument(
                "--master_addresses", help="specify the comma seperated values of current " +
                "masters of the cluster.",
                metavar=""
            )

        # Commands that can alter configuration file.
        for cmd in ("start",):
            cur_parser = all_parsers[cmd]
            cur_parser.add_argument(
                "--ycql_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--ysql_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--master_rpc_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--tserver_rpc_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--master_webserver_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--tserver_webserver_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--webserver_port", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--listen", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--advertise_address",
                help="IP address or local hostname on which {} will listen.".format(SCRIPT_NAME),
                metavar="")
            cur_parser.add_argument(
                "--join", help="IP address to which this process will join".format(SCRIPT_NAME),
                metavar="")
            cur_parser.add_argument(
                "--secure", help="Start a YugabyteDB cluster in secure mode with encryption in " +
                "transit and password authentication enabled. No need to set a value for the " +
                "flag. Use --secure or --insecure flag to toggle security features on a " +
                "YugabyteDB cluster.",
                action="store_true", default=None)
            cur_parser.add_argument(
                "--insecure", help="Start a YugabyteDB cluster in an insecure mode without " +
                "encryption in transit and password authentication enabled. For non-production " +
                "use only, not to be used without firewalls blocking the internet traffic. No " +
                "need to set a value for the flag. Use --secure or --insecure flag to toggle " +
                "security features on a YugabyteDB cluster.", action="store_true", default=None)
            cur_parser.add_argument(
                "--certs_dir", help="Path to the certificates to be used for secure deployment.",
                metavar="")
            cur_parser.add_argument(
                "--daemon", choices=BOOL_CHOICES, help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--background", choices=BOOL_CHOICES, metavar="",
                help="Runs {} in the background as a daemon. Does not persist on restart. "
                     "Default true.".format(SCRIPT_NAME))
            cur_parser.add_argument(
                "--callhome", choices=BOOL_CHOICES,
                help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--ui", choices=BOOL_CHOICES, metavar="",
                help="Toggle enabling or disabling webserver UI. Default true.")
            cur_parser.add_argument(
                "--ysql_enable_auth", choices=BOOL_CHOICES,
                help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--use_cassandra_authentication", choices=BOOL_CHOICES,
                help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--initial_scripts_dir", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--cloud_location", metavar="",
                help="Cloud location of the node in form of cloudprovider.region.zone")
            cur_parser.add_argument(
                "--fault_tolerance", metavar="",
                help="Determines the type of deployment of the cluster. Default is None.")

            # Hidden commands for development/advanced users
            cur_parser.add_argument(
                "--polling_interval", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--master_flags", help=argparse.SUPPRESS)
            cur_parser.add_argument(
                "--tserver_flags", help=argparse.SUPPRESS)


        if not sys.argv[1:]:
            parser.print_help()
            return

        args = parser.parse_args()
        self.validate_and_set_parent_configs(args)
        # Yugabyted command currently being processed is required for
        # generating the status string.
        self.configs.temp_data["yugabyted_cmd"] = args.parser

        log_dir = self.configs.saved_data.get("log_dir")
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)

        Output.log_dir = log_dir
        logging.basicConfig(
            level=logging.DEBUG, filemode="a",
            filename=os.path.join(log_dir, "{}.log".format(SCRIPT_NAME)),
            format="[%(filename)s " + args.parser + "] %(asctime)s %(levelname)s: %(message)s")

        Output.log("cmd = {} using config file: {} (args.config={})".format(
            args.parser, self.conf_file, args.config))

        # Initialize the script path of openssl_proxy.sh
        OpenSSLProxy.init()

        # Initialize the binary path of ybadmin
        YBAdminProxy.init()

        self.validate_and_set_configs(args)

        # Initialize the binary path of ybadmin
        # TODO(Sanket): Clean up and refactor this file
        YBAdminProxy.set_certs_dir(self.configs.saved_data.get("master_flags"), \
            self.configs.saved_data.get("secure"), self.configs.saved_data.get("certs_dir"))

        try:
            args.func()
        except Exception as e:
            Output.print_out(
                "{} crashed. For troubleshooting, contact us on {} or check our FAQ at {}".format(
                    SCRIPT_NAME, Output.make_underline(SLACK_LINK),
                    Output.make_underline(HELP_LINK)))
            Output.log_error_and_exit(traceback.format_exc())

    def advertise_ip(self):
        bind_ip = self.configs.saved_data.get("advertise_address")
        return bind_ip if bind_ip != IP_ANY else IP_LOCALHOST

    def master_port(self):
       self.configs.saved_data.get("master_rpc_port")

    def first_install_init_auth(self):
        if self.get_failed_node_processes():
            Output.log_error_and_exit(
                "{} is not running.".format(SCRIPT_NAME))

        if self.setup_env_init.is_exists('YSQL_USER') or \
                self.setup_env_init.is_exists('YSQL_PASSWORD') or \
                self.setup_env_init.is_exists('YSQL_DB'):
            ysql_proxy = YsqlProxy(ip=self.advertise_ip(),
                            port=self.configs.saved_data.get("ysql_port"),
                            get_default_credentials=True)
            if retry_op(ysql_proxy.is_ysql_up):
                Output.log("Setting up custom credentials for YSQL...")
                self.setup_env_init.setup_ysql_credentials(ysql_proxy)

        if self.setup_env_init.is_exists('YCQL_USER') or \
                self.setup_env_init.is_exists('YCQL_PASSWORD') or \
                self.setup_env_init.is_exists('YCQL_KEYSPACE'):
            ycql_proxy = YcqlProxy(ip=self.advertise_ip(),
                            port=self.configs.saved_data.get("ycql_port"),
                            get_default_credentials=True)
            if retry_op(ycql_proxy.is_ycql_up):
                Output.log("Setting up custom credentials for YCQL...")
                self.setup_env_init.setup_ycql_credentials(ycql_proxy)

        if self.configs.temp_data.get("initial_scripts_dir"):
            init_scripts = os.path.abspath(self.configs.temp_data.get("initial_scripts_dir"))

            if os.path.exists(init_scripts):
                Output.log("Initialization scripts from the {} directory".format(init_scripts))

                sql_files = sorted([sql_file for sql_file in os.listdir(init_scripts) if (
                                sql_file.endswith('.sql'))])
                cql_files = sorted([cql_file for cql_file in os.listdir(init_scripts) if (
                                cql_file.endswith('.cql'))])

                ysql_proxy = YsqlProxy(ip=self.advertise_ip(),
                                port=self.configs.saved_data.get("ysql_port"))
                if sql_files and retry_op(ysql_proxy.is_ysql_up):
                    self.load_init_scripts(ysql_proxy, init_scripts, sql_files)

                ycql_proxy = YcqlProxy(ip=self.advertise_ip(),
                                port=self.configs.saved_data.get("ycql_port"))
                if cql_files and retry_op(ycql_proxy.is_ycql_up):
                    self.load_init_scripts(ycql_proxy, init_scripts, cql_files)

    def load_init_scripts(self, proxy_class, init_scripts_dir, files):
        files_path = []
        for name in files:
            files_path.append(os.path.join(init_scripts_dir, name))

        proxy_class.load_files(files_path)

class Configs(object):
    def __init__(self, config_file, base_dir):
        self.saved_data = {
            "data_dir": os.path.join(base_dir, "data"),
            "log_dir": os.path.join(base_dir, "logs"),
            "gen_certs_dir": os.path.join(base_dir, "generated_certs"),
            "master_rpc_port": DEFAULT_MASTER_RPC_PORT,
            "tserver_rpc_port": DEFAULT_TSERVER_RPC_PORT,
            "master_webserver_port": DEFAULT_MASTER_WEBSERVER_PORT,
            "tserver_webserver_port": DEFAULT_TSERVER_WEBSERVER_PORT,
            "ysql_port": DEFAULT_YSQL_PORT,
            "ycql_port": DEFAULT_YCQL_PORT,
            "advertise_address": "",
            "webserver_port": DEFAULT_WEBSERVER_PORT,
            "yugabyted_ui_port": DEFAULT_YUGABYTED_UI_PORT,
            "universe_uuid": str(uuid.uuid4()),
            "node_uuid": str(uuid.uuid4()),
            "tserver_uuid": str(uuid.uuid4()).replace("-", ""),
            "master_uuid": str(uuid.uuid4()).replace("-", ""),
            "polling_interval": "5",
            "callhome": DEFAULT_CALLHOME,
            "master_flags": "",
            "tserver_flags": "",
            "join": "",
            "ysql_enable_auth": False,
            "use_cassandra_authentication": False,
            "cloud_provider": DEFAULT_CLOUD_PROVIDER,
            "cloud_region": DEFAULT_CLOUD_REGION,
            "cloud_zone": DEFAULT_CLOUD_ZONE,
            "fault_tolerance": DEFAULT_START_FAULT_TOLERANCE,
            "secure": False,
            "insecure": True,
            "certs_dir": os.path.join(base_dir, "certs"),
            "ca_cert_file_path": "",
            "database_password": None,
            "current_masters": "",
            "ui": True,
            "dns_enabled": False,
        }
        # Used to store data specific to certain functions that we don't want to save.
        self.temp_data = {
            "demo_db": DEFAULT_DEMO_DATABASE,
            "background": True,
            "initial_scripts_dir": "",
            "collect_logs_stdout": False,
            "constraint_value": "",
            "replication_factor":"",
            "fault_tolerance": DEFAULT_FAULT_TOLERANCE,
            "hostnames": "",
            "enable_encrypt_at_rest": False,
            "disable_encrypt_at_rest": False,
            "admin_command": "",
            "admin_operation_master_addresses":"",
        }
        self.config_file = config_file

    # Saves current configs to config file.
    def save_configs(self):
        with open(self.config_file, "w+") as f:
            json.dump(self.saved_data, f, indent=4)

    # Custom parser for reading config file.
    @staticmethod
    def parse_config_file(config_file, base_dir):
        configs = Configs(config_file, base_dir)
        if os.path.isfile(config_file):
            try:
                with open(config_file) as f:
                   configs.saved_data.update(json.load(f))
            except ValueError as e:
                Output.log_error_and_exit(
                    "Failed to read config file {}: {}".format(config_file, str(e)))

        paths = ["data_dir", "log_dir", "certs_dir", "gen_certs_dir", "ca_cert_file_path"]
        for k, v in configs.saved_data.items():
            if v is not None and k in paths:
                configs.saved_data[k] = os.path.expanduser(v)

        return configs

    @staticmethod
    def get_brew_config():
        # hack alert: we are using the cellar dir name to identify a brew install
        if ("darwin" == sys.platform and
            os.path.realpath(sys.argv[0]).lower().find('cellar') >= 0 and
            os.path.exists(BREW_CONF_FILE)):
            return BREW_CONF_FILE

        return None

    # Returns information about demo databases.
    @staticmethod
    def get_demo_info():
        return {
            "retail": {
                "files": ("schema.sql", "products.sql", "users.sql", "reviews.sql", "orders.sql"),
                "output": "    Database: yb_demo_retail\n"
                        "    |_ users\n"
                        "    |_ products\n"
                        "    |_ orders\n"
                        "    |_ reviews\n\n",
                "examples": "# JOINS (find user details of orders):\n"
                        "    %s users.id, users.name, users.email, orders.id, orders.total\n"
                        "        %s orders %s users %s orders.user_id=users.id\n"
                        "        %s 10;\n\n" % tuple([Output.make_cyan(kw) for kw in (
                            "SELECT", "FROM", "INNER JOIN", "ON", "LIMIT")])
            },
            "northwind": {
                "files": ("northwind_ddl.sql", "northwind_data.sql"),
                "output": "",
                "examples": "# JOINS (find customer details for orders):\n"
                        "   %s c.customer_id, c.company_name, o.order_id, o.order_date\n"
                        "       %s orders o %s customers c %s o.customer_id=c.customer_id\n"
                        "       %s 10;\n\n" % tuple([Output.make_cyan(kw) for kw in (
                            "SELECT", "FROM", "INNER JOIN", "ON", "LIMIT")])
            },
            "club": {
                "files": ("clubdata_ddl.sql", "clubdata_data.sql"),
                "output": "",
                "examples": ""
            },
            "sports": {
                "files": (
                    "sportsdb_tables.sql", "sportsdb_fks.sql",
                    "sportsdb_indexes.sql", "sportsdb_inserts.sql"),
                "output": "",
                "examples": ""
            }
        }


class ProcessManager(object):
    def __init__(self, name, cmd, log_dir, data_dir, process_log_dir=""):
        self.name = name
        self.cmd = cmd
        self.log_dir = log_dir
        self.data_dir = data_dir
        self.pidfile = os.path.join(self.data_dir, "{}.pid".format(name))
        self.process = None
        self.start_time = None
        self.process_log_dir = process_log_dir

    # Start process. Creates pidfile and corresponding output logs.
    def start(self):
        Output.log("About to start {} with cmd {}".format(self.name, " ".join(self.cmd)))
        out_log = os.path.join(self.log_dir, "{}.out".format(self.name))
        err_log = os.path.join(self.log_dir, "{}.err".format(self.name))
        with open(out_log, "a") as out_log, open(err_log, "a") as err_log:
            self.process = subprocess.Popen(
                self.cmd, stdout=out_log, stderr=err_log, preexec_fn=self.set_rlimits)
            self.start_time = time.time()
        self.write_pid(self.process.pid)

        # Add symlink to the logs from log directory.
        log_path = os.path.join(self.log_dir, self.name)
        if self.process_log_dir and not os.path.exists(log_path):
            try:
                os.symlink(self.process_log_dir, log_path)
            except OSError as e:
                Output.log(
                    "Failed to create symlink from {} to {}".format(self.process_log_dir, log_path),
                    logging.ERROR)

    # Records given pid in pidfile.
    # TODO: Redirect YW logs to yugabyte-logs
    def write_pid(self, pid):
        with open(self.pidfile, "w+") as pid_file:
            pid_file.write(str(pid))
            Output.log("{} started running with PID {}.".format(self.name, pid))

    # Returns pid of this process if it's running.
    def get_pid(self):
        if os.path.exists(self.pidfile):
            if self.process:
                return self.process.pid
            else:
                with open(self.pidfile, "r") as f:
                    try:
                        pid = int(f.readline())
                    except ValueError as e:
                        Output.log(
                            "Could not parse int PID from {}. Deleting file.".format(self.pidfile),
                            logging.DEBUG)
                        self.delete_pidfile()
                        return None
                command = ProcessManager.get_command(pid)
                if command and self.name.encode('utf8') in command:
                    return pid

            Output.log(
                "Pidfile {} was not properly deleted."
                "Contained PID {}. Deleting file.".format(self.pidfile, pid), logging.DEBUG)
            self.delete_pidfile()
        return None

    # Kills self.process if it exists.
    def kill(self):
        err = None
        pid = None
        if self.process:
            self.process.kill()
        else:
            pid = self.get_pid()
            if pid:
                try:
                    os.kill(pid, SIGTERM)
                except OSError as e:
                    return (e, pid)
        self.delete_pidfile()
        return (err, pid)

    # Raise RetryableError if pidfile still exists.
    def is_proc_running(self, pid):
        if (os.path.exists(self.pidfile) or ProcessManager.get_command(pid) != ""):
            raise RetryableError()
        else:
            return True

    # Function that waits until pidfile no longer exists.
    def wait_until_stop(self, pid):
        def temp_func():
            return self.is_proc_running(pid)
        retry_op(temp_func, timeout=60)
        return

    # Delete corresponding pidfile for this process.
    def delete_pidfile(self):
        if os.path.exists(self.pidfile):
            try:
                os.remove(self.pidfile)
            except OSError as e:
                if os.path.exists(self.pidfile):
                    Output.log(
                        "Failed to delete {}.".format(self.pidfile), level=logging.ERROR)
        self.start_time = None

    # Check fatal errors in fatal/error logs, if any. Overwritten in YBProcessManager
    def check_fatals(self):
        pass

    # Returns process status.
    def is_running(self):
        self.check_fatals()
        return self.get_pid() and self.process and self.process.poll() is None

    # Checks resource settings for current shell. Prints warning if requirements aren't met.
    def set_rlimits(self, print_info=False):
        rlim_max = resource.RLIM_INFINITY
        # TODO: Figure out what specs are recommended. max_user_processes is problematic.
        # https://github.com/yugabyte/yugabyte-db/issues/2818
        recommended_resources = {
            # "RLIMIT_FSIZE": (rlim_max, "file_size"),
            # "RLIMIT_MEMLOCK": (rlim_max, "max_locked_memory"),
            # "RLIMIT_AS": (rlim_max, "max_memory_size"),
            "RLIMIT_NOFILE": (1048576, "open_files"),
            # "RLIMIT_CPU": (rlim_max, "cpu_time"),
            "RLIMIT_NPROC": (MAX_PROC[OS_NAME], "max_user_processes"),
            # "RLIMIT_VMEM": (rlim_max, "virtual_memory"),
        }

        # If the current platform does not support the resource,
        # it won't be defined in the resource module.
        failed = []
        for res, (min_val, ulimit) in recommended_resources.items():
            if not hasattr(resource, res):
                continue
            # Check soft limit, not hard limit.
            key = getattr(resource, res)
            soft_lim, hard_lim = resource.getrlimit(key)
            if soft_lim != rlim_max and (soft_lim < min_val or min_val == rlim_max):
                try:
                    resource.setrlimit(key, (min_val, hard_lim))
                    if print_info:
                        Output.log("Changed {} from {} to {}".format(res, soft_lim, min_val))
                except ValueError as e:
                    failed.append((ulimit, soft_lim, min_val))
                    if print_info:
                        Output.log(
                            "Error changing {} from {} to {}: {}".format(
                                res, soft_lim, min_val, e),
                            logging.ERROR)

        if failed and print_info:
            return list(zip(*failed))[0]

    # Returns the command that was run with the input pid.
    @staticmethod
    def get_command(pid):
        try:
            return subprocess.check_output(["ps", "-p", str(pid), "-o", "command="])
        except subprocess.CalledProcessError as e:
            return ""

    # Returns if process called name is running.
    @staticmethod
    def is_process_running(name, pid_dir):
        return ProcessManager(name, cmd="", log_dir="", data_dir=pid_dir).get_pid() is not None


# Class for managing yugabyted process components - e.g. pidfiles and lockfiles.
# Maybe this class can take over the ControlScript.start_processes functionality?
class ScriptProcessManager(ProcessManager):
    def __init__(self, log_dir, data_dir):
        super(ScriptProcessManager, self).__init__(SCRIPT_NAME, "", log_dir, data_dir)
        # Used to retrieve status of daemon process. When daemon successfully initializes,
        # it will put a value here which can be checked on.
        self.daemon_success = multiprocessing.Queue()

    def start(self):
        return

    def is_running(self):
        pid = self.get_pid()
        # In certain scenarios like docker, the pid of a previously crashed docker run
        # is going to be 1, which is the same as ours and looks like the previous run is
        # still ongoing. The getpid check below covers that case.
        # In the long run, the plan is to move to something like flock instead.
        return pid is not None and pid != os.getpid()


class YBProcessManager(ProcessManager):
    def __init__(self, name, cmd, log_dir, data_dir):
        data_log_path = "{}/yb-data/{}/logs".format(data_dir, name)
        super(YBProcessManager, self).__init__(name, cmd, log_dir, data_dir, data_log_path)
        self.error_log = "{}/yb-{}.ERROR".format(data_log_path, name)


    def start(self):
        # Remove old logs as timestamped logs should have already been created.
        self.remove_error_logs()

        super(YBProcessManager, self).start()

    def remove_error_logs(self):
        if os.path.isfile(self.error_log):
            os.remove(self.error_log)

    def check_fatals(self):
        # Error logs contain port information, but fatal logs don't.
        address_error_1 = "Could not start on address"
        address_error_2 = "Error binding socket to "
        address_error_3 = "Is another postmaster already running on port "
        if os.path.isfile(self.error_log):
            with open(self.error_log) as log:
                for line in log.readlines():
                    if address_error_1 in line:
                        err_msg = line.split(address_error_1)
                        # Try to find address, otherwise log entire error message.
                        if len(err_msg) == 2:
                            err_msg = err_msg[1]
                        else:
                            err_msg = line
                        Output.log_error_and_exit(
                            "Failed to bind to address: {}".format(err_msg))
                    elif address_error_2 in line:
                        err_msg = line.split(address_error_2)[1]
                        address = err_msg.split()[0]
                        Output.log_error_and_exit(
                            "Failed to bind to address: {}".format(address))
                    elif address_error_3 in line:
                        err_msg = line.split(address_error_3)
                        # Try to find address, otherwise log entire error message.
                        if len(err_msg) == 2:
                            err_msg = err_msg[1].split()[0]
                            Output.log_error_and_exit(
                                "Failed to bind to port: {}.".format(err_msg))
                        else:
                            Output.log_error_and_exit(
                                "Failed to bind to address: {}".format(err_msg))


class Diagnostics(object):
    first_install = None
    first_run_secs = None

    def __init__(self, configs):
        self.configs = configs

    # Collects data.
    def get_data(self, processes):
        payload = {
            "data_dir_size": self.get_dir_size(self.configs.saved_data.get("data_dir")),
            "num_cpus": multiprocessing.cpu_count(),
            "master_flags": self.configs.saved_data.get("master_flags"),
            "tserver_flags": self.configs.saved_data.get("tserver_flags"),
            "is_docker" : str(os.path.exists("/.dockerenv"))
        }
        if Diagnostics.first_install is not None:
            payload['first_install'] = str(Diagnostics.first_install)
            Diagnostics.first_install = None
        if Diagnostics.first_run_secs is not None:
            payload['first_run_secs'] = str(int(Diagnostics.first_run_secs))
            Diagnostics.first_run_secs = None
        for p in processes.values():
            payload["{}_status".format(p.name)] = "UP" if p.is_running() else "DOWN"
            if p.start_time:
                payload["{}_start_time".format(p.name)] = p.start_time

        bind_ip = self.configs.saved_data.get("advertise_address")
        advertise_ip = bind_ip if bind_ip != IP_ANY else IP_LOCALHOST

        master_addrs = "{}:{}".format(
            advertise_ip, self.configs.saved_data.get("master_rpc_port"))
        # TODO: This is going to change for multi-node.
        cur_master_addr = master_addrs
        data = {
            "cluster_uuid": self.configs.saved_data.get("universe_uuid"),
            "node_uuid": self.configs.saved_data.get("node_uuid"),
            "server_type": SCRIPT_NAME,
            "timestamp": int(time.time()),
            "payload": payload
        }
        return json.dumps(data)

    def get_dir_size(self, dirname):
        size = 0
        for path, _, files in os.walk(dirname):
            for f in files:
                filepath = os.path.join(path, f)
                # Check that the file is not a symlink
                if os.path.isfile(filepath):
                    size += os.path.getsize(filepath)
        return size


# Proxy for parsing output from yb-admin commands.
class YBAdminProxy(object):
    cmd_args = []

    @staticmethod
    def init():
        YBAdminProxy.cmd_args.append(find_binary_location("yb-admin"))

    @staticmethod
    def set_certs_dir(master_flags, secure, certs_dir):
        # If the user is attempting to use TLS, let's point yb-admin to
        # the same certs dir as the master
        if secure:
            YBAdminProxy.cmd_args.append("--certs_dir_name={}".format(certs_dir))
        elif master_flags:
            flags_list = master_flags.split(",")
            if 'use_node_to_node_encryption=true' not in flags_list:
                return
            certs_dir_name = [y for y in
                [re.match('certs_dir=(.*)', x) for x in flags_list]
                if y is not None]
            if not certs_dir_name[0]:
                raise RuntimeError("use_node_to_node_encryption=true must "
                                "be accompanied by a certs_dir setting")
            YBAdminProxy.cmd_args.append('--certs_dir_name={}'.format(certs_dir_name[0].group(1)))

    @staticmethod
    def add_master(master_addrs, new_master_ip, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--init_master_addrs", master_addrs,
              "change_master_config", "ADD_SERVER", new_master_ip, "7100"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (0 == ret_code)

    @staticmethod
    def remove_master(master_addrs, old_master, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--init_master_addrs", master_addrs,
              "change_master_config", "REMOVE_SERVER", old_master, "7100"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (0 == ret_code)

    @staticmethod
    def set_rf(master_addrs, rf, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--init_master_addrs", master_addrs,
                "modify_placement_info", "cloud1.datacenter1.rack1", str(rf) ]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (0 == ret_code)

    @staticmethod
    # Returns [ (uuid, ip:port, role) ] for each master
    def get_masters(master_addrs, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--master_addresses", master_addrs, "list_all_masters"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        if 0 != ret_code or len(out.splitlines()) <= 1:
            return []
        masters = [ line.split() for line in out.splitlines()[1:] ]
        return [ (master[0], master[1], master[3]) for master in masters ]

    # Returns list[tserver uuid] reported by yb-master.
    @staticmethod
    def get_tservers(master_addrs, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--master_addresses", master_addrs,
                "list_all_tablet_servers"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        if 0 != ret_code or len(out.splitlines()) <= 1:
            return None
        return [ line.split()[0] for line in out.splitlines()[1:] ]

    # Returns the cluster_uuid for this universe
    @staticmethod
    def get_cluster_uuid(master_addrs):
        cluster_config = YBAdminProxy.get_cluster_config(master_addrs)
        if cluster_config:
            return cluster_config['clusterUuid']
        else:
            return None

    # Returns the rf for this universe
    @staticmethod
    def get_cluster_rf(master_addrs):
        cluster_config = YBAdminProxy.get_cluster_config(master_addrs)
        if cluster_config:
            if "replicationInfo" in cluster_config:

                return cluster_config["replicationInfo"]["liveReplicas"]["numReplicas"]
            else:
                return 1
        else:
            return None

    # Returns the cluster config for this universe
    @staticmethod
    def get_cluster_config(master_addrs, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["--master_addresses", master_addrs, "get_universe_config"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        if ret_code:
            return None
        try:
            return json.loads(out)
        except Exception:
            return None

    # Returns node_uuid by finding the UUID corresponding to current master's IP
    @staticmethod
    def get_node_uuid(master_addrs, cur_master_addr):
        cmd = YBAdminProxy.cmd_args + ["--init_master_addrs", master_addrs, "list_all_masters"]
        out, err, ret_code = run_process(cmd)
        if ret_code:
            return None
        for line in out.splitlines()[1:]:
            master_uuid, rpc_addr, _, _ = line.split()
            if rpc_addr == cur_master_addr:
                return master_uuid
        return None

    # Sets placement info
    @staticmethod
    def modify_placement_info(master_addrs, placement_locations, replication_factor = "3",
                              timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs, "modify_placement_info",
                placement_locations, replication_factor]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (ret_code == 0)

    # Copy universe key to all masters for encryption at rest
    @staticmethod
    def copy_key_to_masters(master_addrs, key_id, key_path, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs,
            "add_universe_key_to_all_masters", key_id, key_path]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (ret_code == 0)

    # Check if universe key has been copied to all masters for encryption at rest
    @staticmethod
    def check_key_in_masters(master_addrs, key_id, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs,
            "all_masters_have_universe_key_in_memory", key_id]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        if 0 != ret_code:
            return []
        out = out.splitlines()
        return out

    # Enable encryption at rest by start using the key in masters
    @staticmethod
    def enable_encryption_using_key(master_addrs, key_id, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs,
            "rotate_universe_key_in_memory", key_id]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (ret_code == 0)

    # Disable encryption at rest
    @staticmethod
    def disable_encryption(master_addrs, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs, "disable_encryption"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        return (ret_code == 0)

    # Check if universe key has been copied to all masters for encryption at rest
    @staticmethod
    def check_encryption(master_addrs, timeout=10):
        cmd = YBAdminProxy.cmd_args + ["-master_addresses", master_addrs, "is_encryption_enabled"]
        out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
        if 0 != ret_code:
            return None
        return out

    # Passthrough method for all the yb-admin commands
    # @staticmethod
    # def call_yb_admin_command(master_addrss, command, timeout=10):
    #     cmd =  YBAdminProxy.cmd_args + ["-master_addresses", master_addrss, command]
    #     out, err, ret_code = run_process(cmd, timeout=timeout, log_cmd=True)
    #     if 0 != ret_code:
    #         return None
    #     return out


# Proxy for ysqlsh commands.
class YsqlProxy(object):
    def __init__(self, ip, port, path=None,
                    get_default_credentials=False):
        if path is None:
            path = find_binary_location(YUGABYTE_API_CLIENT_PROGRAMS["ysql"])
        self.setup_env_init = EnvBasedCredentials()
        self.username, self.password, self.db = self.setup_env_init.get_ysql_credentials(
                                                    get_default_credentials)
        self.cmd_with_password = [path, "postgresql://{}:{}@{}:{}".format(self.username,
                self.password, ip, port)]
        self.cmd_without_password = [path, "-h", str(ip), "-p", str(port)]
        env_var = os.environ.copy()
        env_var["PGUSER"] = self.username
        env_var["PGPASSWORD"] = self.password
        env_var["PGDATABASE"] = self.db

        self.env = env_var

    # Starts interactive YSQL shell.
    def connect(self, db=None):
        if db is None:
            db = self.db
        cmd = self.cmd_without_password + ["-d", db]
        env_var = os.environ.copy()
        env_var["PGUSER"] = self.username
        shell = subprocess.Popen(cmd, env=env_var)
        while True:
            try:
                shell.communicate()
            except KeyboardInterrupt:
                continue
            break

    # Checks if db exists.
    # Note that this will return false if ysqlsh can't connect, even if db exists.
    def db_exists(self, db):
        cmd = self.cmd_with_password + ["-q", "-c", "\\t", "-c",
            "select datname from pg_catalog.pg_database where datname='{}'".format(db)]
        return run_process_checked(cmd=cmd, env_vars=self.env).strip() == db

    # Creates specified db.
    def create_db(self, db):
        cmd = self.cmd_with_password + ["-c", "create database \"{}\"".format(db)]
        run_process_checked(cmd=cmd, env_vars=self.env)

    # Deletes specified db.
    def drop_db(self, db):
        cmd = self.cmd_with_password + ["-c", "drop database {}".format(db)]
        run_process_checked(cmd=cmd, env_vars=self.env)

    # Runs ysqlsh with specified files.
    def load_files(self, filepaths, db=None):
        cmd = self.cmd_with_password
        env = self.env
        if db:
            env['PGDATABASE'] = db
        else:
            env['PGDATABASE'] = self.db
        for path in filepaths:
            cmd.extend(["-f", path])
        run_process_checked(cmd=cmd, log_cmd=False, env_vars=env)

    # Check user exists
    # Note that this will return false if ysqlsh can't connect, even if user exists.
    def user_exists(self, ysql_username):
        cmd = self.cmd_with_password + \
                ["-c", "select rolname from pg_catalog.pg_roles where rolname='{}'".
                format(ysql_username)]
        run_process_checked(cmd=cmd, env_vars=self.env).strip() == ysql_username

    # Create specified superuser
    def create_user(self, ysql_username, ysql_password):
        cmd = self.cmd_with_password + \
                ["-c", "create role \"{}\" with LOGIN SUPERUSER password '{}';".
                format(ysql_username, ysql_password)]
        run_process_checked(cmd=cmd, log_cmd=False, env_vars=self.env)

    # Delete specified user
    def delete_user(self, username, password, user_to_delete=DEFAULT_YSQL_USER):
        cmd = self.cmd_with_password + ["-c", "drop role {};".format(user_to_delete)]
        env = self.env
        env['PGUSER'] = username
        env['PGPASSWORD'] = password
        run_process_checked(cmd=cmd, env_vars=env)

    # Update specified user's password
    def update_password(self, new_password, user_to_update=DEFAULT_YSQL_USER):
        cmd = self.cmd_with_password + \
            ["-c", "alter role {} password '{}';".format(user_to_update, new_password)]
        run_process_checked(cmd=cmd, log_cmd=False, env_vars=self.env)

    # Try to update specified user's password otherwise throw Retryable Error
    def try_update_password(self, new_password, user_to_update=DEFAULT_YSQL_USER):
        cmd = self.cmd_with_password + \
            ["-c", "alter role {} password '{}';".format(user_to_update, new_password)]

        encrypted_password = "*" * len(new_password)
        encrypted_cmd = self.cmd_with_password + \
            ["-c", "alter role {} password '{}';".format(user_to_update, encrypted_password)]

        out, err, retcode = run_process(cmd=cmd, encrypted_cmd=encrypted_cmd, log_cmd=True,
                env_vars=self.env)
        if (retcode != 0):
            raise RetryableError

    # Change specified DB's owner
    def db_owner(self, db, new_owner):
        cmd = self.cmd_with_password + \
            ["-c", "alter database \"{}\" owner to \"{}\";".format(db, new_owner)]
        run_process_checked(cmd=cmd, env_vars=self.env)

    # Check YSQL is UP
    def is_ysql_up(self):
        cmd = self.cmd_with_password + ["-c", "\\conninfo"]
        out, err, _ = run_process(cmd=cmd, log_cmd=True, env_vars=self.env)
        if err:
            Output.log("Unable to connect using YSQL. Error: {}".format(err))
            raise RetryableError()
        else:
            Output.log("YSQL Connection Info - {}".format(out))
            return True

# Proxy for ycqlsh commands.
class YcqlProxy(object):
    def __init__(self, ip, port, path=None,
                    get_default_credentials=False, secure=False):
        if path is None:
            path = find_binary_location(YUGABYTE_API_CLIENT_PROGRAMS["ycql"])
        self.cmd = [path, str(ip), str(port)]
        self.setup_env_init = EnvBasedCredentials()
        self.username, self.password, self.keyspace = self.setup_env_init.get_ycql_credentials(
                                                        get_default_credentials)
        self.password_authentication=secure

        if secure:
            self.cmd.append("--ssl")

    # Starts interactive YCQL shell.
    def connect(self):
        cmd = self.cmd
        if self.password_authentication:
            cmd.extend(["-u", self.username])
        if self.keyspace is not None:
            cmd.extend(["-k", self.keyspace])
        shell = subprocess.Popen(cmd)
        while True:
            try:
                shell.communicate()
            except KeyboardInterrupt:
                continue
            break

    # Check user exists
    # Note that this will return false if ycqlsh can't connect, even if user exists.
    def user_exists(self, ycql_username):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
            "SELECT role FROM system_auth.roles WHERE role='{}';".format(ycql_username)]
        return run_process_checked(cmd).strip() == ycql_username

    # Create specified superuser
    def create_user(self, ycql_username, ycql_password):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
                "CREATE ROLE \"{}\" WITH PASSWORD = '{}' AND LOGIN = true AND SUPERUSER = true;".
                format(ycql_username, ycql_password)]
        run_process_checked(cmd, log_cmd=False)

    # Delete specified user
    def delete_user(self, username, password, user_to_delete=DEFAULT_YCQL_USER):
        cmd = self.cmd + ["-u", username, "-p", password, "-e",
                "DROP ROLE IF EXISTS {};".format(user_to_delete)]
        run_process_checked(cmd)

    # Update specified user's password
    def update_password(self, new_password, user_to_update=DEFAULT_YCQL_USER):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
                "ALTER ROLE {} WITH PASSWORD = '{}';".format(user_to_update, new_password)]
        run_process_checked(cmd, log_cmd=False)

    # Try to update specified user's password otherwise throw Retryable Error
    def try_update_password(self, new_password, user_to_update=DEFAULT_YCQL_USER):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
                "ALTER ROLE {} WITH PASSWORD = '{}';".format(user_to_update, new_password)]

        encrypted_password = "*" * len(new_password)
        encrypted_cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
                "ALTER ROLE {} WITH PASSWORD = '{}';".format(user_to_update, encrypted_password)]

        out, err, retcode = run_process(cmd=cmd, encrypted_cmd=encrypted_cmd, log_cmd=True,
                env_vars=os.environ.copy())
        if (retcode != 0):
            raise RetryableError

    # Check keyspace exists
    # Note that this will return false if ycqlsh can't connect, even if keyspace exists.
    def keyspace_exists(self, keyspace):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
            "SELECT keyspace_name FROM system_schema.keyspaces WHERE keyspace_name='{}';".
            format(keyspace)]
        return run_process_checked(cmd).strip() == keyspace

    # Create specified keyspace
    def create_keyspace(self, keyspace):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e",
                "CREATE KEYSPACE \"{}\";".format(keyspace)]
        run_process_checked(cmd)

    # Runs ycqlsh with specified files.
    # Example:
    # 1. bin/ycqlsh -f directory/a.ycql
    # 2. If environment variables exists: bin/ycqlsh -u user -p password -f directory/b.ycql
    def load_files(self, filepaths):
        cmd = self.cmd
        cmd.extend(["-u", self.username, "-p", self.password])
        for path in filepaths:
            cmd.extend(["-f", path])
        run_process_checked(cmd=cmd, log_cmd=False)

    # Check YCQL is UP
    def is_ycql_up(self):
        cmd = self.cmd + ["-u", self.username, "-p", self.password, "-e", "SHOW HOST"]
        out, err, _ = run_process(cmd, log_cmd=True)
        if err:
            Output.log("Unable to connect using YCQL. Error: {}".format(err))
            raise RetryableError()
        else:
            Output.log("YCQL Connection Info - {}".format(out))
            return True


# Proxy for creating ssl certificates and keys using openssl
class OpenSSLProxy(object):
    cmd_args = []

    @staticmethod
    def init(path=None):
        if path is None:
            path = find_binary_location("openssl_proxy.sh")

        OpenSSLProxy.cmd_args = [path]

    # Generate root ca certificates
    @staticmethod
    def generate_root_ca_certs(root_certs_dir, timeout=60):
        cmd = OpenSSLProxy.cmd_args + ['generate-ca', '-rcp', root_certs_dir]
        out, err, ret = run_process(cmd, timeout=timeout, log_cmd=True)

        return (0 == ret)

    # Generate node server certificates
    @staticmethod
    def generate_node_server_certs(root_certs_dir, server_cert_dir, hostname, timeout=60):
        cmd = OpenSSLProxy.cmd_args + ['generate-server-cert', '-rcp', root_certs_dir,
            '-scp', server_cert_dir, '-hn', hostname]
        out, err, ret = run_process(cmd, timeout=timeout, log_cmd=True)

        return (0 == ret)

    # Generate universe key for encryption-at-rest
    @staticmethod
    def generate_key(key_dir, keyname, timeout=60):
        cmd = OpenSSLProxy.cmd_args + ['generate-key', '-kp', key_dir, '-kn', keyname]
        out, err, ret = run_process(cmd, timeout=timeout, log_cmd=True)

        return (0 == ret)


# Currently unused. Useful for getting diagnostics that are available only through logs.
class LogAnalyzer(object):
    unsupported_error = "not supported yet"
    def __init__(self, logfile):
        self.logfile = logfile
        # Flag to stop tailing the logfile.
        self.kill_thread = False
        self.unsupported_commands = []

    def analyze(self):
        lines = self.tail()
        for line in lines:
            if LogAnalyzer.unsupported_error in line:
                # Get the command logged right before error message
                cmd = line.split("not supported yet")[0].split()[-1]
                self.unsupported_commands.append(cmd)

    # Generator that continually returns last line of logfile.
    def tail(self):
        with open(self.logfile) as open_file:
            open_file.seek(0, 2)
            while not self.kill_thread:
                line = open_file.readline()
                if not line:
                    time.sleep(0.1)
                    continue
                yield line

# Manages API calls to YW.
class YugaWareProxy(object):
    def __init__(self, ip, webserver_port, univ_name="local-universe"):
        self.univ_name = univ_name
        self.api_token_secure = ""
        self.api_token_insecure = ""
        self.cust_uuid = ""
        self.url = "http://{}:{}/api/v1".format(ip, webserver_port)

    # Retrieves permanent api_token. Returns error, if any.
    def login(self):
        try:
            target = "{}/login".format(self.url)
            headers = {
                "Content-Type": "application/json",
            }
            data = urlencode({"email": "admin", "password": "admin"})
            req = Request(target, data=data.encode('utf8'))
            resp = urlopen(req)
            session_data = json.loads(resp.read())
            auth_token = session_data["authToken"]
            self.cust_uuid = session_data["customerUUID"]
            # Auth token will expire, so get API token instead.
            target = "{}/customers/{}/api_token".format(self.url, self.cust_uuid)
            headers = {
                "X-Auth-Token": auth_token,
            }
            req = Request(target, headers=headers)
            req.get_method = lambda: "PUT"
            resp = urlopen(req)
            api_data = json.loads(resp.read())
            self.api_token_secure = api_data["apiToken"]
            return None
        except (ValueError, HTTPError, URLError, KeyError) as e:
            return "Failed to log into webserver. {}".format(e)

    # Attempts insecure login. Returns error, if any.
    def insecure_login(self):
        try:
            target = "{}/insecure_login".format(self.url)
            req = Request(target)
            resp = urlopen(req)
            session_data = json.loads(resp.read())
            self.api_token_insecure = session_data["apiToken"]
            self.cust_uuid = session_data["customerUUID"]
            return None
        except (ValueError, HTTPError, URLError, KeyError) as e:
            return "Failed to log into webserver. {}".format(e)

    # Import local universe into YW. Returns error, if any.
    def import_universe(self, master_address, master_rpc_port, universeUUID):
        target = "{}/customers/{}/universes/import".format(self.url, self.cust_uuid)
        headers = {
            "X-AUTH-YW-API-TOKEN": self.api_token_secure,
            "Content-Type": "application/json",
        }
        data = {
            "cloudProviderType": "other",
            "currentState": "BEGIN",
            "masterAddresses": "{}".format(master_address),
            "universeName": self.univ_name,
            "universeUUID": universeUUID,
            "singleStep": "true",
        }

        Output.log("Importing Yugabyte into webserver...")
        try:
            Output.log("Importing master.", logging.DEBUG)
            req = Request(target, headers=headers, data=json.dumps(data).encode('utf8'))
            resp = json.loads(urlopen(req).read())
            checks = resp.get("checks")
            Output.log("Import master payload: req: {}, resp: {}".format(req, resp))
            if universeUUID != resp.get("universeUUID"):
                Output.log(
                    "Failed to import local universe into webserver: invalid uuid: {}".format(resp),
                    logging.ERROR)
            # Node exporter does not matter for local universes and will fail on import.
            if "node_exporter_ip_error_map" in checks:
                del[checks["node_exporter_ip_error_map"]]
            if checks and not all(check == 'OK' for check in checks.values()):
                Output.log(
                    ("Failed to import local universe into webserver, "
                     "checks failed: {}").format(resp))

        except (ValueError, HTTPError, URLError, KeyError) as e:
            return "Failed to import local universe into YW with payload: {}.\n" \
                "Got error: {}".format(data, e)

        Output.log("Import completed.")
        return None

    # Disables/hides paid services on UI.
    def set_landing_page(self, universe_uuid):
        target = "{}/customers/{}/features".format(self.url, self.cust_uuid)
        headers = {
            "X-AUTH-YW-API-TOKEN": self.api_token_secure,
            "Content-Type": "application/json",
        }
        data = {
            "features": {
                "main": {
                    "landing_page": "universes/{}".format(universe_uuid),
                    "universe_list": "disabled"
                }
            }
        }

        err_msg = None
        Output.log("Setting UI landing page...")
        try:
            req = Request(target, headers=headers, data=json.dumps(data).encode('utf8'))
            req.get_method = lambda: "PUT"
            resp = urlopen(req)
            if resp.code != 200:
                err_msg = "Failed setting landing page with error code: {}.".format(resp.code)
        except (ValueError, HTTPError, URLError, KeyError) as e:
            err_msg = "Failed to set landing page: {}".format(e)

        if not err_msg:
            Output.log("Successfully set landing page.")
        else:
            Output.log(err_msg, logging.ERROR)
        return err_msg

    # Sets YugaWare to input security level.
    def set_security(self, level):
        target = "{}/customers/{}/security".format(self.url, self.cust_uuid)
        headers = {
            "X-AUTH-YW-API-TOKEN": self.api_token_secure,
            "Content-Type": "application/json",
        }
        data = {"level": level}
        err_msg = None
        Output.log("Updating YW security to {}...".format(level))
        try:
            req = Request(target, headers=headers, data=json.dumps(data).encode('utf8'))
            req.get_method = lambda: "PUT"
            resp = urlopen(req)
            if resp.code != 200:
                err_msg = "Failed to set security level. YW returned code: " + resp.code
        except (ValueError, HTTPError, URLError, KeyError) as e:
            err_msg = "Failed to set security level: {}".format(e)

        if not err_msg:
            Output.log("Sucesssfully set YW security to {}".format(level))
        else:
            Output.log(err_msg, logging.ERROR)
        return err_msg

    # Add alerts to YugaWare.
    def send_alerts(self, alerts):
        target = "{}/customers/{}/alerts".format(self.url, self.cust_uuid)
        headers = {
            "X-AUTH-YW-API-TOKEN": self.api_token_secure,
            "Content-Type": "application/json",
        }
        Output.log("Adding alerts: {}".format(alerts))
        for alert in alerts:
            data = {
                "type": alert[0],
                "errCode": alert[1],
                "message": alert[2]
            }
            try:
                req = Request(target, headers=headers, data=json.dumps(data).encode('utf8'))
                req.get_method = lambda: "PUT"
                resp = urlopen(req)
                if resp.code != 200:
                    Output.log(
                        "Got error code {} when adding alert: {}".format(resp.code, alert),
                        logging.ERROR)
            except (ValueError, HTTPError, URLError, KeyError) as e:
                Output.log("Failed adding alert {} with error: {}".format(alert, e), logging.ERROR)
        del alerts[:]


# Class that handles any output operations. Use print for what users should see.
# Use log for logging. ANSI escape characters should not be used for logging.
class Output(object):
    supports_color = (sys.platform != 'win32' or 'ANSICON' in os.environ) and \
        hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()
    END = "\u001b[0m"
    BOLD = "\u001b[1m"
    UNDERLINE = "\u001b[4m"
    RED = "\u001b[31m"
    GREEN = "\u001b[32m"
    YELLOW = "\u001b[33m"
    BLUE = "\u001b[34m"
    MAGENTA = "\u001b[35m"
    CYAN = "\u001b[36m"
    # Transform to an "extended ASCII" library to parse the string then print it as unicode
    ROCKET = "\xf0\x9f\x9a\x80".encode('latin1').decode('utf8')
    PARTY = "\xf0\x9f\x8e\x89".encode('latin1').decode('utf8')
    SHIRT = "\xf0\x9f\x91\x95".encode('latin1').decode('utf8')
    log_dir = None
    script_exit_func = None
    # Only attempt to write to stdout while we have access to console.
    console_access = True

    ANIMATION_SUCCESS = '\u2705'
    ANIMATION_FAIL = '\u274C'
    ANIMATION_RUNNING = 1
    ANIMATION_WARNING = '\u26A0'
    # Tuple of (animation_status, animation_message) to ensure atomicity.
    animation_status = (ANIMATION_SUCCESS, "")
    animation_thread = None

    @staticmethod
    def print_out(msg):
        if not Output.console_access:
            return

        try:
            try:
                if PY_VERSION < 3:
                    print(msg.encode('utf8'))
                else:
                    print(msg)
            except UnicodeEncodeError:
                print(msg.encode('ascii', 'ignore').decode())
        except Exception as e:
            # Ignore any print errors as they are not critical to the application.
            Output.log("Failed to print with error: {}".format(traceback.format_exc()))

    # Writes one line that may be replaced with the update_animation method.
    # Note - ONLY one line can be replaced. E.g. only characters after a newline can be replaced.
    @staticmethod
    def init_animation(msg):
        if not Output.console_access:
            return

        def animate():
            loading_symbols = ['/', '-', '\\', '|']
            line_len = 0
            i = 0
            running = True
            while running and Output.console_access:
                status, msg = Output.animation_status
                if status == Output.ANIMATION_RUNNING:
                    symbol = loading_symbols[i]
                else:
                    symbol = status
                    running = False

                line = "\r{} {}".format(symbol, msg)
                line_len = max(len(line), line_len)
                line_to_write = "{:<{}}".format(line, line_len)
                if not running:
                    line_to_write += "\n"

                try:
                    try:
                        if PY_VERSION < 3:
                            sys.stdout.write(line_to_write.encode('utf-8'))
                        else:
                            sys.stdout.write(line_to_write)
                    except UnicodeEncodeError:
                        sys.stdout.write(line_to_write.encode('ascii', 'ignore').decode())

                    try:
                        sys.stdout.flush()
                    except IOError as e:
                        Output.log("Errored when flushing stdout: {}".format(e), logging.ERROR)
                    i = (i + 1) % len(loading_symbols)
                except Exception as e:
                    # Ignore stdout write errors as they are not critical to application.
                    Output.log("Failed stdout write with error: {}".format(traceback.format_exc()))

                time.sleep(.05)

        Output.animation_status = (Output.ANIMATION_RUNNING, msg)
        Output.animation_thread = Thread(target=animate)
        Output.animation_thread.start()

    @staticmethod
    def update_animation(msg, status=ANIMATION_SUCCESS):
        if not Output.console_access:
            return

        if not Output.animation_thread:
            Output.print_out(msg)

        Output.animation_status = (status, msg)
        if status != Output.ANIMATION_RUNNING and Output.animation_thread:
            Output.animation_thread.join()
            Output.animation_thread = None

    @staticmethod
    def log(msg, level=logging.INFO):
        if '' == msg or msg is None:
            return

        full_msg = msg
        time_since_sec = time.time() - start_time_sec
        if time_since_sec < 1000:
            # add time since start to make it easier to debug startup perf
            full_msg = " | {:.1f}s | {}".format(time_since_sec, msg)
        try:
            logging.log(level, full_msg)
        except:
            pass

    @staticmethod
    def print_and_log(msg, level=logging.INFO):
        Output.log(msg, level=level)
        Output.print_out(msg)

    @staticmethod
    def log_error_and_exit(msg):
        if Output.log_dir:
            msg += "\nFor more information, check the logs in {}".format(Output.log_dir)
        Output.print_and_log(msg, logging.ERROR)
        Output.console_access = False
        if Output.script_exit_func:
            Output.script_exit_func()
        sys.exit(1)

    @staticmethod
    def make_bold(msg):
        return Output.BOLD + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_underline(msg):
        return Output.UNDERLINE + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_red(msg):
        return Output.RED + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_green(msg):
        return Output.GREEN + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_yellow(msg):
        return Output.YELLOW + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_blue(msg):
        return Output.BLUE + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_magenta(msg):
        return Output.MAGENTA + msg + Output.END if Output.supports_color else msg

    @staticmethod
    def make_cyan(msg):
        return Output.CYAN + msg + Output.END if Output.supports_color else msg


# Class to customize argparse output.
class PrettyArgParser(argparse.ArgumentParser):
    def __init__(self, **kwargs):
        kwargs["formatter_class"] = PrettyHelpFormatter
        kwargs["epilog"] = EPILOG_COMMON
        super(PrettyArgParser, self).__init__(**kwargs)
        self._positionals.title = Output.make_yellow("Commands")
        self._optionals.title = Output.make_yellow("Flags")

    # Add epilog help message to errors.
    def error(self, message):
        Output.print_out("{} {}.".format(Output.make_red("Error:"), message))
        self.print_help(sys.stderr)
        self.exit(2)


# Class that capitalizes argparse help message.
class PrettyHelpFormatter(argparse.RawTextHelpFormatter):
    # Add prefix of cli title and change "Usage" to yellow
    # Add usage according to the command from which help is called
    def add_usage(self, usage, actions, groups, prefix=None):
        cmd = ('%(prog)s' % dict(prog=self._prog)).split()
        for cmds in ['[command]', '[flags]']:
            if cmds in cmd:
                cmd.remove(cmds)
        if len(cmd) > 2:
            temp = ""
            for cmds in cmd[1:]:
                temp += cmds + " "
            cmd = temp.strip()
        else:
            cmd = cmd.pop()
        if prefix is None:
            prefix = get_cli_title()
            prefix += PREFIX[cmd] + "\n\n"
            prefix += Output.make_yellow('Usage') + ": "
        if usage is None:
            usage = USAGE[cmd]
        super(PrettyHelpFormatter, self).add_usage(
            usage, actions, groups, prefix)

    # Sort the flags in alphabetical order for the help message
    def add_arguments(self, actions):
        actions = sorted(actions, key=operator.attrgetter('option_strings'))
        super(PrettyHelpFormatter, self).add_arguments(actions)

    # Remove the help under "Command" section which had all command inside curly braces
    def _format_action(self, action):
        result = super(PrettyHelpFormatter,
                       self)._format_action(action)
        if isinstance(action, argparse._SubParsersAction):
            return "%*s%s" % (self._current_indent, "", result.lstrip())
        return result

    # Remove the help under "Command" section which had all command inside curly braces
    def _iter_indented_subactions(self, action):
        if isinstance(action, argparse._SubParsersAction):
            try:
                get_subactions = action._get_subactions
            except AttributeError:
                pass
            else:
                for subaction in get_subactions():
                    yield subaction
        else:
            for subaction in super(PrettyHelpFormatter,
                                   self)._iter_indented_subactions(action):
                yield subaction

# Returns key-value pairs of input dict. Independent of python version.
def get_kv(map):
    if PY_VERSION < 3:
        return map.iteritems()
    else:
        return map.items()

def run_process(cmd, encrypted_cmd=None, timeout=None, log_cmd=False, env_vars=None, shell=False):
    if log_cmd:
        if encrypted_cmd:
            Output.log("run_process: cmd: {}".format(str(encrypted_cmd)))
        else:
            Output.log("run_process: cmd: {}".format(str(cmd)))

    proc = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE,
                            env=env_vars, shell=shell)
    if PY_VERSION >= 3:
        try:
            out, err = proc.communicate(timeout=timeout)
        except subprocess.TimeoutExpired as e:
            if encrypted_cmd:
                Output.log("run_process: {} timeout expired for command: ".format(encrypted_cmd))
            else:
                Output.log("run_process: {} timeout expired for command: ".format(cmd))
            return None, str(e), -1
    else:
        out, err = proc.communicate()
    (ret_out, ret_err, retcode) = (out.decode('utf-8'), err.decode('utf-8'), proc.returncode)
    if log_cmd:
        Output.log("run_process returned {}: \nOUT >>\n{}\n<< ERR >>\n{}\n<<".format(
            retcode, ret_out, ret_err))
    return (ret_out, ret_err, retcode)

def run_process_checked(cmd, timeout=None, log_cmd=True, env_vars=None):
    out, err, retcode = run_process(cmd=cmd, timeout=timeout, log_cmd=log_cmd, env_vars=env_vars)
    if retcode:
        Output.log_error_and_exit("Error: {}".format(err))
    return out

def rmcontents(dirname, exclude_names=[]):
    for f in os.listdir(dirname):
        if f in exclude_names:
            continue
        fullpath = os.path.join(dirname, f)
        if os.path.islink(fullpath) or os.path.isfile(fullpath):
            os.unlink(fullpath)
            continue
        if os.path.isdir(fullpath):
            shutil.rmtree(fullpath)
            continue
        Output.log("Unexpected type of file : [ {} ]".format(fullpath))


class RetryableError(Exception):
    pass

# Retry as long as func throws RetryableError.
def retry_op(func, timeout=180):
    start_time = time.time()
    now = start_time
    while True:
        try:
            return func()
        except RetryableError:
            pass
        now = time.time()
        if now - start_time > timeout:
            break
        time.sleep(0.5)

    raise RuntimeError("Failed after retrying operation for {} secs.".format(
        now - start_time))

# Retry the function with argument as long as func throws RetryableError.
def retry_op_with_argument(func, argument, timeout=180):
    start_time = time.time()
    now = start_time
    while True:
        try:
            return func(argument)
        except RetryableError:
            pass
        now = time.time()
        if now - start_time > timeout:
            break
        time.sleep(0.5)

    raise RuntimeError("Failed after retrying operation for {} secs.".format(
        now - start_time))


class EnvBasedCredentials(object):
    _ysql_user = os.environ.get('YSQL_USER')
    _ysql_password = os.environ.get('YSQL_PASSWORD')
    _ysql_db = os.environ.get('YSQL_DB')
    _ycql_user = os.environ.get('YCQL_USER')
    _ycql_password = os.environ.get('YCQL_PASSWORD')
    _ycql_keyspace = os.environ.get('YCQL_KEYSPACE')
    _cert_file_path = os.environ.get('SSL_CERTFILE')

    def attrsetter(attr):
        def set_any(self, value):
            setattr(type(self), attr, value)
        return set_any

    def attrgetter(attr):
        def get_any(self):
            return getattr(self, attr)
        return get_any

    ysql_user = property(attrgetter('_ysql_user'), attrsetter('_ysql_user'))
    ysql_password = property(attrgetter('_ysql_password'), attrsetter('_ysql_password'))
    ysql_db = property(attrgetter('_ysql_db'), attrsetter('_ysql_db'))
    ycql_user = property(attrgetter('_ycql_user'), attrsetter('_ycql_user'))
    ycql_password = property(attrgetter('_ycql_password'), attrsetter('_ycql_password'))
    ycql_keyspace = property(attrgetter('_ycql_keyspace'), attrsetter('_ycql_keyspace'))
    cert_file_path = property(attrgetter('_cert_file_path'), attrsetter('_cert_file_path'))

    def get_ysql_user(self):
        return self.ysql_user or DEFAULT_YSQL_USER

    def get_ysql_password(self):
        return self.ysql_password or (self.ysql_user or DEFAULT_YSQL_PASSWORD)

    def get_ysql_db(self):
        return self.ysql_db or (self.ysql_user or DEFAULT_YSQL_DB)

    def get_ycql_user(self):
        return self.ycql_user or DEFAULT_YCQL_USER

    def get_ycql_password(self):
        return self.ycql_password or (self.ycql_user or DEFAULT_YCQL_PASSWORD)

    def get_ycql_keyspace(self):
        return self.ycql_keyspace or (self.ycql_user or DEFAULT_YCQL_KEYSPACE)

    def get_cert_file_path(self):
        return self.cert_file_path

    def get_ysql_credentials(self, get_default_credentials=False):
        if get_default_credentials:
            return DEFAULT_YSQL_USER, DEFAULT_YSQL_PASSWORD, DEFAULT_YSQL_DB
        else:
            return self.get_ysql_user(), self.get_ysql_password(), self.get_ysql_db()

    def get_ycql_credentials(self, get_default_credentials=False):
        if get_default_credentials:
            return DEFAULT_YCQL_USER, DEFAULT_YCQL_PASSWORD, DEFAULT_YCQL_KEYSPACE
        else:
            return self.get_ycql_user(), self.get_ycql_password(), self.get_ycql_keyspace()

    def is_exists(self, var_to_check):
        return True if var_to_check in os.environ and os.environ.get(var_to_check) else False

    def update_ysql_password(self, new_password):
        self.ysql_password = new_password

    def update_ycql_password(self, new_password):
        self.ycql_password = new_password

    def update_passwords(self, new_password):
        self.update_ysql_password(new_password)
        self.update_ycql_password(new_password)

    def setup_ysql_credentials(self, proxy_class):

        # Create DB
        if self.get_ysql_db() != DEFAULT_YSQL_DB and not proxy_class.db_exists(self.get_ysql_db()):
            proxy_class.create_db(self.get_ysql_db())

        # Update password for default user
        if self.get_ysql_user() == DEFAULT_YSQL_USER and self.get_ysql_password() != DEFAULT_YSQL_PASSWORD:
            proxy_class.update_password(self.get_ysql_password())

        # Create User
        if self.get_ysql_user() != DEFAULT_YSQL_USER and not proxy_class.user_exists(self.get_ysql_user()):
            proxy_class.create_user(self.get_ysql_user(), self.get_ysql_password())

            if self.get_ysql_db() != DEFAULT_YSQL_DB:
                proxy_class.db_owner(self.get_ysql_db(), self.get_ysql_user())

            # Note: Following lines will be commented till we can decide on default user deletion.
            #proxy_class.delete_user(self.get_ysql_user(), self.get_ysql_password())

    def setup_ycql_credentials(self, proxy_class):

        # Create YCQL Keyspace
        if self.get_ycql_keyspace() and not proxy_class.keyspace_exists(self.get_ycql_keyspace()):
            proxy_class.create_keyspace(self.get_ycql_keyspace())

        # Update password for default user
        if self.get_ycql_user() == DEFAULT_YCQL_USER and self.get_ycql_password() != DEFAULT_YCQL_PASSWORD:
            proxy_class.update_password(self.get_ycql_password())

        # Create user
        if self.get_ycql_user() != DEFAULT_YCQL_USER and not proxy_class.user_exists(self.get_ycql_user()):
            proxy_class.create_user(self.get_ycql_user(), self.get_ycql_password())

            # Note: Following lines will be commented till we can decide on default user deletion.
            #proxy_class.delete_user(self.get_ycql_user(), self.get_ycql_password())

    def setup_cert_file_path(self, cert_file_path):
        if self.get_cert_file_path() is None or self.get_cert_file_path != cert_file_path:
            os.environ['SSL_CERTFILE'] = cert_file_path
            self.cert_file_path = cert_file_path


if __name__ == '__main__':
    ControlScript().run()
